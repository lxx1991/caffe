I0713 17:35:53.970674  6493 caffe.cpp:217] Using GPUs 0
I0713 17:35:54.000095  6493 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0713 17:35:54.288296  6493 solver.cpp:50] Initializing solver from parameters: 
test_iter: 720
test_interval: 200
base_lr: 0.001
display: 10
max_iter: 9000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 6000
snapshot: 2000
snapshot_prefix: "examples/DPN_VOC/model/unary"
solver_mode: GPU
device_id: 0
net: "examples/DPN_VOC/DPN_VOC.prototxt"
train_state {
  level: 0
  stage: ""
}
pavi_log: true
pavi_server_host: "pavi.parrotsdnn.org"
pavi_username: "xxli"
pavi_password: "123456"
session: "DPN_VOC_unary"
workdir: "examples/DPN_VOC/"
I0713 17:35:54.288553  6493 solver.cpp:98] Creating training net from net file: examples/DPN_VOC/DPN_VOC.prototxt
I0713 17:35:54.289996  6493 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0713 17:35:54.290410  6493 net.cpp:58] Initializing net from parameters: 
name: "DPN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 480
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
    crop_resize: 0.8
    crop_resize: 1
    label_crop_size: 96
  }
  image_data_param {
    source: "data/VOC_arg/train.txt"
    batch_size: 10
    shuffle: true
    root_folder: "data/VOC_arg"
    label_type: PIXEL
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-VOC"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-VOC"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "fc8-VOC"
  top: "upscore"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 21
    bias_term: false
    pad: 4
    kernel_size: 16
    group: 21
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upscore"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
    hm_ratio: 0.5
  }
}
I0713 17:35:54.290702  6493 layer_factory.hpp:77] Creating layer data
I0713 17:35:54.290776  6493 net.cpp:100] Creating Layer data
I0713 17:35:54.290794  6493 net.cpp:408] data -> data
I0713 17:35:54.290848  6493 net.cpp:408] data -> label
I0713 17:35:54.291313  6493 image_seg_data_layer.cpp:45] Opening file data/VOC_arg/train.txt
I0713 17:35:54.311583  6493 image_seg_data_layer.cpp:101] Shuffling data
I0713 17:35:54.311841  6493 image_seg_data_layer.cpp:106] A total of 10582 images.
I0713 17:35:54.351557  6493 image_seg_data_layer.cpp:179] output data size: 10,3,480,480
I0713 17:35:54.351598  6493 image_seg_data_layer.cpp:183] output label size: 10,1,288,288
I0713 17:35:54.429214  6493 net.cpp:150] Setting up data
I0713 17:35:54.429322  6493 net.cpp:157] Top shape: 10 3 480 480 (6912000)
I0713 17:35:54.429335  6493 net.cpp:157] Top shape: 10 1 288 288 (829440)
I0713 17:35:54.429343  6493 net.cpp:165] Memory required for data: 30965760
I0713 17:35:54.429360  6493 layer_factory.hpp:77] Creating layer conv1_1
I0713 17:35:54.429404  6493 net.cpp:100] Creating Layer conv1_1
I0713 17:35:54.429419  6493 net.cpp:434] conv1_1 <- data
I0713 17:35:54.429443  6493 net.cpp:408] conv1_1 -> conv1_1
I0713 17:35:54.431579  6493 net.cpp:150] Setting up conv1_1
I0713 17:35:54.431602  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.431609  6493 net.cpp:165] Memory required for data: 620789760
I0713 17:35:54.431635  6493 layer_factory.hpp:77] Creating layer relu1_1
I0713 17:35:54.431653  6493 net.cpp:100] Creating Layer relu1_1
I0713 17:35:54.431663  6493 net.cpp:434] relu1_1 <- conv1_1
I0713 17:35:54.431674  6493 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0713 17:35:54.431691  6493 net.cpp:150] Setting up relu1_1
I0713 17:35:54.431702  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.431710  6493 net.cpp:165] Memory required for data: 1210613760
I0713 17:35:54.431716  6493 layer_factory.hpp:77] Creating layer conv1_2
I0713 17:35:54.431730  6493 net.cpp:100] Creating Layer conv1_2
I0713 17:35:54.431738  6493 net.cpp:434] conv1_2 <- conv1_1
I0713 17:35:54.431751  6493 net.cpp:408] conv1_2 -> conv1_2
I0713 17:35:54.433773  6493 net.cpp:150] Setting up conv1_2
I0713 17:35:54.433797  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.433805  6493 net.cpp:165] Memory required for data: 1800437760
I0713 17:35:54.433821  6493 layer_factory.hpp:77] Creating layer relu1_2
I0713 17:35:54.433835  6493 net.cpp:100] Creating Layer relu1_2
I0713 17:35:54.433845  6493 net.cpp:434] relu1_2 <- conv1_2
I0713 17:35:54.433856  6493 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0713 17:35:54.433867  6493 net.cpp:150] Setting up relu1_2
I0713 17:35:54.433876  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.433883  6493 net.cpp:165] Memory required for data: 2390261760
I0713 17:35:54.433890  6493 layer_factory.hpp:77] Creating layer pool1
I0713 17:35:54.433902  6493 net.cpp:100] Creating Layer pool1
I0713 17:35:54.433909  6493 net.cpp:434] pool1 <- conv1_2
I0713 17:35:54.433920  6493 net.cpp:408] pool1 -> pool1
I0713 17:35:54.438539  6493 net.cpp:150] Setting up pool1
I0713 17:35:54.438567  6493 net.cpp:157] Top shape: 10 64 240 240 (36864000)
I0713 17:35:54.438575  6493 net.cpp:165] Memory required for data: 2537717760
I0713 17:35:54.438582  6493 layer_factory.hpp:77] Creating layer conv2_1
I0713 17:35:54.438599  6493 net.cpp:100] Creating Layer conv2_1
I0713 17:35:54.438607  6493 net.cpp:434] conv2_1 <- pool1
I0713 17:35:54.438619  6493 net.cpp:408] conv2_1 -> conv2_1
I0713 17:35:54.439668  6493 net.cpp:150] Setting up conv2_1
I0713 17:35:54.439689  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.439697  6493 net.cpp:165] Memory required for data: 2832629760
I0713 17:35:54.439756  6493 layer_factory.hpp:77] Creating layer relu2_1
I0713 17:35:54.439770  6493 net.cpp:100] Creating Layer relu2_1
I0713 17:35:54.439779  6493 net.cpp:434] relu2_1 <- conv2_1
I0713 17:35:54.439788  6493 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0713 17:35:54.439801  6493 net.cpp:150] Setting up relu2_1
I0713 17:35:54.439813  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.439820  6493 net.cpp:165] Memory required for data: 3127541760
I0713 17:35:54.439826  6493 layer_factory.hpp:77] Creating layer conv2_2
I0713 17:35:54.439842  6493 net.cpp:100] Creating Layer conv2_2
I0713 17:35:54.439851  6493 net.cpp:434] conv2_2 <- conv2_1
I0713 17:35:54.439862  6493 net.cpp:408] conv2_2 -> conv2_2
I0713 17:35:54.440248  6493 net.cpp:150] Setting up conv2_2
I0713 17:35:54.440264  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.440271  6493 net.cpp:165] Memory required for data: 3422453760
I0713 17:35:54.440284  6493 layer_factory.hpp:77] Creating layer relu2_2
I0713 17:35:54.440294  6493 net.cpp:100] Creating Layer relu2_2
I0713 17:35:54.440301  6493 net.cpp:434] relu2_2 <- conv2_2
I0713 17:35:54.440311  6493 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0713 17:35:54.440322  6493 net.cpp:150] Setting up relu2_2
I0713 17:35:54.440331  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.440337  6493 net.cpp:165] Memory required for data: 3717365760
I0713 17:35:54.440346  6493 layer_factory.hpp:77] Creating layer pool2
I0713 17:35:54.440354  6493 net.cpp:100] Creating Layer pool2
I0713 17:35:54.440361  6493 net.cpp:434] pool2 <- conv2_2
I0713 17:35:54.440371  6493 net.cpp:408] pool2 -> pool2
I0713 17:35:54.440420  6493 net.cpp:150] Setting up pool2
I0713 17:35:54.440433  6493 net.cpp:157] Top shape: 10 128 120 120 (18432000)
I0713 17:35:54.440440  6493 net.cpp:165] Memory required for data: 3791093760
I0713 17:35:54.440446  6493 layer_factory.hpp:77] Creating layer conv3_1
I0713 17:35:54.440460  6493 net.cpp:100] Creating Layer conv3_1
I0713 17:35:54.440467  6493 net.cpp:434] conv3_1 <- pool2
I0713 17:35:54.440479  6493 net.cpp:408] conv3_1 -> conv3_1
I0713 17:35:54.442416  6493 net.cpp:150] Setting up conv3_1
I0713 17:35:54.442443  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.442451  6493 net.cpp:165] Memory required for data: 3938549760
I0713 17:35:54.442469  6493 layer_factory.hpp:77] Creating layer relu3_1
I0713 17:35:54.442482  6493 net.cpp:100] Creating Layer relu3_1
I0713 17:35:54.442489  6493 net.cpp:434] relu3_1 <- conv3_1
I0713 17:35:54.442500  6493 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0713 17:35:54.442513  6493 net.cpp:150] Setting up relu3_1
I0713 17:35:54.442523  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.442530  6493 net.cpp:165] Memory required for data: 4086005760
I0713 17:35:54.442538  6493 layer_factory.hpp:77] Creating layer conv3_2
I0713 17:35:54.442553  6493 net.cpp:100] Creating Layer conv3_2
I0713 17:35:54.442560  6493 net.cpp:434] conv3_2 <- conv3_1
I0713 17:35:54.442571  6493 net.cpp:408] conv3_2 -> conv3_2
I0713 17:35:54.444605  6493 net.cpp:150] Setting up conv3_2
I0713 17:35:54.444628  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.444636  6493 net.cpp:165] Memory required for data: 4233461760
I0713 17:35:54.444648  6493 layer_factory.hpp:77] Creating layer relu3_2
I0713 17:35:54.444659  6493 net.cpp:100] Creating Layer relu3_2
I0713 17:35:54.444667  6493 net.cpp:434] relu3_2 <- conv3_2
I0713 17:35:54.444677  6493 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0713 17:35:54.444690  6493 net.cpp:150] Setting up relu3_2
I0713 17:35:54.444700  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.444705  6493 net.cpp:165] Memory required for data: 4380917760
I0713 17:35:54.444722  6493 layer_factory.hpp:77] Creating layer conv3_3
I0713 17:35:54.444736  6493 net.cpp:100] Creating Layer conv3_3
I0713 17:35:54.444743  6493 net.cpp:434] conv3_3 <- conv3_2
I0713 17:35:54.444754  6493 net.cpp:408] conv3_3 -> conv3_3
I0713 17:35:54.446813  6493 net.cpp:150] Setting up conv3_3
I0713 17:35:54.446835  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.446843  6493 net.cpp:165] Memory required for data: 4528373760
I0713 17:35:54.446856  6493 layer_factory.hpp:77] Creating layer relu3_3
I0713 17:35:54.446871  6493 net.cpp:100] Creating Layer relu3_3
I0713 17:35:54.446878  6493 net.cpp:434] relu3_3 <- conv3_3
I0713 17:35:54.446888  6493 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0713 17:35:54.446902  6493 net.cpp:150] Setting up relu3_3
I0713 17:35:54.446910  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.446918  6493 net.cpp:165] Memory required for data: 4675829760
I0713 17:35:54.446923  6493 layer_factory.hpp:77] Creating layer pool3
I0713 17:35:54.446934  6493 net.cpp:100] Creating Layer pool3
I0713 17:35:54.446943  6493 net.cpp:434] pool3 <- conv3_3
I0713 17:35:54.446951  6493 net.cpp:408] pool3 -> pool3
I0713 17:35:54.447003  6493 net.cpp:150] Setting up pool3
I0713 17:35:54.447017  6493 net.cpp:157] Top shape: 10 256 60 60 (9216000)
I0713 17:35:54.447023  6493 net.cpp:165] Memory required for data: 4712693760
I0713 17:35:54.447031  6493 layer_factory.hpp:77] Creating layer conv4_1
I0713 17:35:54.447044  6493 net.cpp:100] Creating Layer conv4_1
I0713 17:35:54.447052  6493 net.cpp:434] conv4_1 <- pool3
I0713 17:35:54.447062  6493 net.cpp:408] conv4_1 -> conv4_1
I0713 17:35:54.451524  6493 net.cpp:150] Setting up conv4_1
I0713 17:35:54.451565  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.451572  6493 net.cpp:165] Memory required for data: 4786421760
I0713 17:35:54.451586  6493 layer_factory.hpp:77] Creating layer relu4_1
I0713 17:35:54.451602  6493 net.cpp:100] Creating Layer relu4_1
I0713 17:35:54.451611  6493 net.cpp:434] relu4_1 <- conv4_1
I0713 17:35:54.451622  6493 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0713 17:35:54.451637  6493 net.cpp:150] Setting up relu4_1
I0713 17:35:54.451647  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.451653  6493 net.cpp:165] Memory required for data: 4860149760
I0713 17:35:54.451659  6493 layer_factory.hpp:77] Creating layer conv4_2
I0713 17:35:54.451675  6493 net.cpp:100] Creating Layer conv4_2
I0713 17:35:54.451686  6493 net.cpp:434] conv4_2 <- conv4_1
I0713 17:35:54.451697  6493 net.cpp:408] conv4_2 -> conv4_2
I0713 17:35:54.459305  6493 net.cpp:150] Setting up conv4_2
I0713 17:35:54.459372  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.459379  6493 net.cpp:165] Memory required for data: 4933877760
I0713 17:35:54.459409  6493 layer_factory.hpp:77] Creating layer relu4_2
I0713 17:35:54.459429  6493 net.cpp:100] Creating Layer relu4_2
I0713 17:35:54.459439  6493 net.cpp:434] relu4_2 <- conv4_2
I0713 17:35:54.459455  6493 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0713 17:35:54.459472  6493 net.cpp:150] Setting up relu4_2
I0713 17:35:54.459484  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.459491  6493 net.cpp:165] Memory required for data: 5007605760
I0713 17:35:54.459497  6493 layer_factory.hpp:77] Creating layer conv4_3
I0713 17:35:54.459513  6493 net.cpp:100] Creating Layer conv4_3
I0713 17:35:54.459522  6493 net.cpp:434] conv4_3 <- conv4_2
I0713 17:35:54.459532  6493 net.cpp:408] conv4_3 -> conv4_3
I0713 17:35:54.467427  6493 net.cpp:150] Setting up conv4_3
I0713 17:35:54.467491  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467499  6493 net.cpp:165] Memory required for data: 5081333760
I0713 17:35:54.467515  6493 layer_factory.hpp:77] Creating layer relu4_3
I0713 17:35:54.467535  6493 net.cpp:100] Creating Layer relu4_3
I0713 17:35:54.467543  6493 net.cpp:434] relu4_3 <- conv4_3
I0713 17:35:54.467558  6493 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0713 17:35:54.467576  6493 net.cpp:150] Setting up relu4_3
I0713 17:35:54.467586  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467592  6493 net.cpp:165] Memory required for data: 5155061760
I0713 17:35:54.467598  6493 layer_factory.hpp:77] Creating layer pool4
I0713 17:35:54.467656  6493 net.cpp:100] Creating Layer pool4
I0713 17:35:54.467664  6493 net.cpp:434] pool4 <- conv4_3
I0713 17:35:54.467676  6493 net.cpp:408] pool4 -> pool4
I0713 17:35:54.467733  6493 net.cpp:150] Setting up pool4
I0713 17:35:54.467747  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467754  6493 net.cpp:165] Memory required for data: 5228789760
I0713 17:35:54.467761  6493 layer_factory.hpp:77] Creating layer conv5_1
I0713 17:35:54.467779  6493 net.cpp:100] Creating Layer conv5_1
I0713 17:35:54.467787  6493 net.cpp:434] conv5_1 <- pool4
I0713 17:35:54.467798  6493 net.cpp:408] conv5_1 -> conv5_1
I0713 17:35:54.475962  6493 net.cpp:150] Setting up conv5_1
I0713 17:35:54.476011  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.476019  6493 net.cpp:165] Memory required for data: 5302517760
I0713 17:35:54.476035  6493 layer_factory.hpp:77] Creating layer relu5_1
I0713 17:35:54.476054  6493 net.cpp:100] Creating Layer relu5_1
I0713 17:35:54.476064  6493 net.cpp:434] relu5_1 <- conv5_1
I0713 17:35:54.476079  6493 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0713 17:35:54.476099  6493 net.cpp:150] Setting up relu5_1
I0713 17:35:54.476107  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.476114  6493 net.cpp:165] Memory required for data: 5376245760
I0713 17:35:54.476120  6493 layer_factory.hpp:77] Creating layer conv5_2
I0713 17:35:54.476136  6493 net.cpp:100] Creating Layer conv5_2
I0713 17:35:54.476148  6493 net.cpp:434] conv5_2 <- conv5_1
I0713 17:35:54.476160  6493 net.cpp:408] conv5_2 -> conv5_2
I0713 17:35:54.484046  6493 net.cpp:150] Setting up conv5_2
I0713 17:35:54.484112  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.484122  6493 net.cpp:165] Memory required for data: 5449973760
I0713 17:35:54.484138  6493 layer_factory.hpp:77] Creating layer relu5_2
I0713 17:35:54.484158  6493 net.cpp:100] Creating Layer relu5_2
I0713 17:35:54.484176  6493 net.cpp:434] relu5_2 <- conv5_2
I0713 17:35:54.484191  6493 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0713 17:35:54.484210  6493 net.cpp:150] Setting up relu5_2
I0713 17:35:54.484220  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.484226  6493 net.cpp:165] Memory required for data: 5523701760
I0713 17:35:54.484233  6493 layer_factory.hpp:77] Creating layer conv5_3
I0713 17:35:54.484248  6493 net.cpp:100] Creating Layer conv5_3
I0713 17:35:54.484261  6493 net.cpp:434] conv5_3 <- conv5_2
I0713 17:35:54.484272  6493 net.cpp:408] conv5_3 -> conv5_3
I0713 17:35:54.492221  6493 net.cpp:150] Setting up conv5_3
I0713 17:35:54.492281  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492290  6493 net.cpp:165] Memory required for data: 5597429760
I0713 17:35:54.492307  6493 layer_factory.hpp:77] Creating layer relu5_3
I0713 17:35:54.492326  6493 net.cpp:100] Creating Layer relu5_3
I0713 17:35:54.492336  6493 net.cpp:434] relu5_3 <- conv5_3
I0713 17:35:54.492350  6493 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0713 17:35:54.492368  6493 net.cpp:150] Setting up relu5_3
I0713 17:35:54.492377  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492383  6493 net.cpp:165] Memory required for data: 5671157760
I0713 17:35:54.492390  6493 layer_factory.hpp:77] Creating layer pool5
I0713 17:35:54.492403  6493 net.cpp:100] Creating Layer pool5
I0713 17:35:54.492409  6493 net.cpp:434] pool5 <- conv5_3
I0713 17:35:54.492419  6493 net.cpp:408] pool5 -> pool5
I0713 17:35:54.492477  6493 net.cpp:150] Setting up pool5
I0713 17:35:54.492491  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492497  6493 net.cpp:165] Memory required for data: 5744885760
I0713 17:35:54.492506  6493 layer_factory.hpp:77] Creating layer pool5a
I0713 17:35:54.492522  6493 net.cpp:100] Creating Layer pool5a
I0713 17:35:54.492530  6493 net.cpp:434] pool5a <- pool5
I0713 17:35:54.492540  6493 net.cpp:408] pool5a -> pool5a
I0713 17:35:54.492573  6493 net.cpp:150] Setting up pool5a
I0713 17:35:54.492583  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492635  6493 net.cpp:165] Memory required for data: 5818613760
I0713 17:35:54.492643  6493 layer_factory.hpp:77] Creating layer fc6-conv
I0713 17:35:54.492660  6493 net.cpp:100] Creating Layer fc6-conv
I0713 17:35:54.492667  6493 net.cpp:434] fc6-conv <- pool5a
I0713 17:35:54.492678  6493 net.cpp:408] fc6-conv -> fc6-conv
I0713 17:35:54.804544  6493 net.cpp:150] Setting up fc6-conv
I0713 17:35:54.804616  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804625  6493 net.cpp:165] Memory required for data: 6030950400
I0713 17:35:54.804643  6493 layer_factory.hpp:77] Creating layer relu6
I0713 17:35:54.804663  6493 net.cpp:100] Creating Layer relu6
I0713 17:35:54.804682  6493 net.cpp:434] relu6 <- fc6-conv
I0713 17:35:54.804699  6493 net.cpp:395] relu6 -> fc6-conv (in-place)
I0713 17:35:54.804750  6493 net.cpp:150] Setting up relu6
I0713 17:35:54.804761  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804769  6493 net.cpp:165] Memory required for data: 6243287040
I0713 17:35:54.804775  6493 layer_factory.hpp:77] Creating layer drop6
I0713 17:35:54.804796  6493 net.cpp:100] Creating Layer drop6
I0713 17:35:54.804808  6493 net.cpp:434] drop6 <- fc6-conv
I0713 17:35:54.804817  6493 net.cpp:395] drop6 -> fc6-conv (in-place)
I0713 17:35:54.804869  6493 net.cpp:150] Setting up drop6
I0713 17:35:54.804883  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804890  6493 net.cpp:165] Memory required for data: 6455623680
I0713 17:35:54.804898  6493 layer_factory.hpp:77] Creating layer fc7-conv
I0713 17:35:54.804913  6493 net.cpp:100] Creating Layer fc7-conv
I0713 17:35:54.804920  6493 net.cpp:434] fc7-conv <- fc6-conv
I0713 17:35:54.804931  6493 net.cpp:408] fc7-conv -> fc7-conv
I0713 17:35:54.855283  6493 net.cpp:150] Setting up fc7-conv
I0713 17:35:54.855345  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855353  6493 net.cpp:165] Memory required for data: 6667960320
I0713 17:35:54.855370  6493 layer_factory.hpp:77] Creating layer relu7
I0713 17:35:54.855389  6493 net.cpp:100] Creating Layer relu7
I0713 17:35:54.855398  6493 net.cpp:434] relu7 <- fc7-conv
I0713 17:35:54.855417  6493 net.cpp:395] relu7 -> fc7-conv (in-place)
I0713 17:35:54.855435  6493 net.cpp:150] Setting up relu7
I0713 17:35:54.855444  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855451  6493 net.cpp:165] Memory required for data: 6880296960
I0713 17:35:54.855458  6493 layer_factory.hpp:77] Creating layer drop7
I0713 17:35:54.855469  6493 net.cpp:100] Creating Layer drop7
I0713 17:35:54.855476  6493 net.cpp:434] drop7 <- fc7-conv
I0713 17:35:54.855485  6493 net.cpp:395] drop7 -> fc7-conv (in-place)
I0713 17:35:54.855523  6493 net.cpp:150] Setting up drop7
I0713 17:35:54.855536  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855543  6493 net.cpp:165] Memory required for data: 7092633600
I0713 17:35:54.855551  6493 layer_factory.hpp:77] Creating layer fc8-VOC
I0713 17:35:54.855571  6493 net.cpp:100] Creating Layer fc8-VOC
I0713 17:35:54.855579  6493 net.cpp:434] fc8-VOC <- fc7-conv
I0713 17:35:54.855590  6493 net.cpp:408] fc8-VOC -> fc8-VOC
I0713 17:35:54.860226  6493 net.cpp:150] Setting up fc8-VOC
I0713 17:35:54.860249  6493 net.cpp:157] Top shape: 10 21 36 36 (272160)
I0713 17:35:54.860257  6493 net.cpp:165] Memory required for data: 7093722240
I0713 17:35:54.860268  6493 layer_factory.hpp:77] Creating layer upscore2
I0713 17:35:54.860288  6493 net.cpp:100] Creating Layer upscore2
I0713 17:35:54.860297  6493 net.cpp:434] upscore2 <- fc8-VOC
I0713 17:35:54.860311  6493 net.cpp:408] upscore2 -> upscore
I0713 17:35:54.860888  6493 net.cpp:150] Setting up upscore2
I0713 17:35:54.860904  6493 net.cpp:157] Top shape: 10 21 288 288 (17418240)
I0713 17:35:54.860910  6493 net.cpp:165] Memory required for data: 7163395200
I0713 17:35:54.860939  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:54.860955  6493 net.cpp:100] Creating Layer loss
I0713 17:35:54.860962  6493 net.cpp:434] loss <- upscore
I0713 17:35:54.861007  6493 net.cpp:434] loss <- label
I0713 17:35:54.861021  6493 net.cpp:408] loss -> loss
I0713 17:35:54.861057  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:54.919119  6493 net.cpp:150] Setting up loss
I0713 17:35:54.919176  6493 net.cpp:157] Top shape: (1)
I0713 17:35:54.919185  6493 net.cpp:160]     with loss weight 1
I0713 17:35:54.919226  6493 net.cpp:165] Memory required for data: 7163395204
I0713 17:35:54.919239  6493 net.cpp:226] loss needs backward computation.
I0713 17:35:54.919252  6493 net.cpp:226] upscore2 needs backward computation.
I0713 17:35:54.919260  6493 net.cpp:226] fc8-VOC needs backward computation.
I0713 17:35:54.919268  6493 net.cpp:226] drop7 needs backward computation.
I0713 17:35:54.919275  6493 net.cpp:226] relu7 needs backward computation.
I0713 17:35:54.919291  6493 net.cpp:226] fc7-conv needs backward computation.
I0713 17:35:54.919297  6493 net.cpp:226] drop6 needs backward computation.
I0713 17:35:54.919304  6493 net.cpp:226] relu6 needs backward computation.
I0713 17:35:54.919311  6493 net.cpp:226] fc6-conv needs backward computation.
I0713 17:35:54.919318  6493 net.cpp:226] pool5a needs backward computation.
I0713 17:35:54.919325  6493 net.cpp:226] pool5 needs backward computation.
I0713 17:35:54.919332  6493 net.cpp:226] relu5_3 needs backward computation.
I0713 17:35:54.919338  6493 net.cpp:226] conv5_3 needs backward computation.
I0713 17:35:54.919345  6493 net.cpp:226] relu5_2 needs backward computation.
I0713 17:35:54.919353  6493 net.cpp:226] conv5_2 needs backward computation.
I0713 17:35:54.919359  6493 net.cpp:226] relu5_1 needs backward computation.
I0713 17:35:54.919366  6493 net.cpp:226] conv5_1 needs backward computation.
I0713 17:35:54.919373  6493 net.cpp:226] pool4 needs backward computation.
I0713 17:35:54.919379  6493 net.cpp:226] relu4_3 needs backward computation.
I0713 17:35:54.919385  6493 net.cpp:226] conv4_3 needs backward computation.
I0713 17:35:54.919392  6493 net.cpp:226] relu4_2 needs backward computation.
I0713 17:35:54.919399  6493 net.cpp:226] conv4_2 needs backward computation.
I0713 17:35:54.919405  6493 net.cpp:226] relu4_1 needs backward computation.
I0713 17:35:54.919411  6493 net.cpp:226] conv4_1 needs backward computation.
I0713 17:35:54.919419  6493 net.cpp:226] pool3 needs backward computation.
I0713 17:35:54.919426  6493 net.cpp:226] relu3_3 needs backward computation.
I0713 17:35:54.919432  6493 net.cpp:226] conv3_3 needs backward computation.
I0713 17:35:54.919440  6493 net.cpp:226] relu3_2 needs backward computation.
I0713 17:35:54.919445  6493 net.cpp:226] conv3_2 needs backward computation.
I0713 17:35:54.919453  6493 net.cpp:226] relu3_1 needs backward computation.
I0713 17:35:54.919459  6493 net.cpp:226] conv3_1 needs backward computation.
I0713 17:35:54.919466  6493 net.cpp:226] pool2 needs backward computation.
I0713 17:35:54.919473  6493 net.cpp:226] relu2_2 needs backward computation.
I0713 17:35:54.919479  6493 net.cpp:226] conv2_2 needs backward computation.
I0713 17:35:54.919486  6493 net.cpp:226] relu2_1 needs backward computation.
I0713 17:35:54.919493  6493 net.cpp:226] conv2_1 needs backward computation.
I0713 17:35:54.919500  6493 net.cpp:226] pool1 needs backward computation.
I0713 17:35:54.919507  6493 net.cpp:226] relu1_2 needs backward computation.
I0713 17:35:54.919513  6493 net.cpp:226] conv1_2 needs backward computation.
I0713 17:35:54.919520  6493 net.cpp:226] relu1_1 needs backward computation.
I0713 17:35:54.919526  6493 net.cpp:226] conv1_1 needs backward computation.
I0713 17:35:54.919534  6493 net.cpp:228] data does not need backward computation.
I0713 17:35:54.919540  6493 net.cpp:270] This network produces output loss
I0713 17:35:54.919581  6493 net.cpp:283] Network initialization done.
I0713 17:35:54.921103  6493 solver.cpp:188] Creating test net (#0) specified by net file: examples/DPN_VOC/DPN_VOC.prototxt
I0713 17:35:54.921198  6493 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0713 17:35:54.921589  6493 net.cpp:58] Initializing net from parameters: 
name: "DPN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 480
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
    label_crop_size: 96
  }
  image_data_param {
    source: "data/VOC_arg/val.txt"
    batch_size: 2
    shuffle: false
    root_folder: "data/VOC_arg"
    label_type: PIXEL
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-VOC"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-VOC"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "fc8-VOC"
  top: "upscore"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 21
    bias_term: false
    pad: 4
    kernel_size: 16
    group: 21
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upscore"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
    hm_ratio: 0.5
  }
}
I0713 17:35:54.921818  6493 layer_factory.hpp:77] Creating layer data
I0713 17:35:54.921857  6493 net.cpp:100] Creating Layer data
I0713 17:35:54.921869  6493 net.cpp:408] data -> data
I0713 17:35:54.921886  6493 net.cpp:408] data -> label
I0713 17:35:54.921905  6493 image_seg_data_layer.cpp:45] Opening file data/VOC_arg/val.txt
I0713 17:35:54.924643  6493 image_seg_data_layer.cpp:106] A total of 1449 images.
I0713 17:35:54.927793  6493 image_seg_data_layer.cpp:179] output data size: 2,3,480,480
I0713 17:35:54.927810  6493 image_seg_data_layer.cpp:183] output label size: 2,1,288,288
I0713 17:35:54.944731  6493 net.cpp:150] Setting up data
I0713 17:35:54.944869  6493 net.cpp:157] Top shape: 2 3 480 480 (1382400)
I0713 17:35:54.944886  6493 net.cpp:157] Top shape: 2 1 288 288 (165888)
I0713 17:35:54.944893  6493 net.cpp:165] Memory required for data: 6193152
I0713 17:35:54.944908  6493 layer_factory.hpp:77] Creating layer conv1_1
I0713 17:35:54.944941  6493 net.cpp:100] Creating Layer conv1_1
I0713 17:35:54.944948  6493 net.cpp:434] conv1_1 <- data
I0713 17:35:54.944964  6493 net.cpp:408] conv1_1 -> conv1_1
I0713 17:35:54.947201  6493 net.cpp:150] Setting up conv1_1
I0713 17:35:54.947228  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.947237  6493 net.cpp:165] Memory required for data: 124157952
I0713 17:35:54.947257  6493 layer_factory.hpp:77] Creating layer relu1_1
I0713 17:35:54.947273  6493 net.cpp:100] Creating Layer relu1_1
I0713 17:35:54.947283  6493 net.cpp:434] relu1_1 <- conv1_1
I0713 17:35:54.947293  6493 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0713 17:35:54.947306  6493 net.cpp:150] Setting up relu1_1
I0713 17:35:54.947315  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.947321  6493 net.cpp:165] Memory required for data: 242122752
I0713 17:35:54.947327  6493 layer_factory.hpp:77] Creating layer conv1_2
I0713 17:35:54.947341  6493 net.cpp:100] Creating Layer conv1_2
I0713 17:35:54.947347  6493 net.cpp:434] conv1_2 <- conv1_1
I0713 17:35:54.947358  6493 net.cpp:408] conv1_2 -> conv1_2
I0713 17:35:54.951216  6493 net.cpp:150] Setting up conv1_2
I0713 17:35:54.951270  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.951278  6493 net.cpp:165] Memory required for data: 360087552
I0713 17:35:54.951308  6493 layer_factory.hpp:77] Creating layer relu1_2
I0713 17:35:54.951330  6493 net.cpp:100] Creating Layer relu1_2
I0713 17:35:54.951340  6493 net.cpp:434] relu1_2 <- conv1_2
I0713 17:35:54.951355  6493 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0713 17:35:54.951375  6493 net.cpp:150] Setting up relu1_2
I0713 17:35:54.951385  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.951392  6493 net.cpp:165] Memory required for data: 478052352
I0713 17:35:54.951398  6493 layer_factory.hpp:77] Creating layer pool1
I0713 17:35:54.951411  6493 net.cpp:100] Creating Layer pool1
I0713 17:35:54.951418  6493 net.cpp:434] pool1 <- conv1_2
I0713 17:35:54.951428  6493 net.cpp:408] pool1 -> pool1
I0713 17:35:54.952373  6493 net.cpp:150] Setting up pool1
I0713 17:35:54.952399  6493 net.cpp:157] Top shape: 2 64 240 240 (7372800)
I0713 17:35:54.952407  6493 net.cpp:165] Memory required for data: 507543552
I0713 17:35:54.952415  6493 layer_factory.hpp:77] Creating layer conv2_1
I0713 17:35:54.952436  6493 net.cpp:100] Creating Layer conv2_1
I0713 17:35:54.952445  6493 net.cpp:434] conv2_1 <- pool1
I0713 17:35:54.952458  6493 net.cpp:408] conv2_1 -> conv2_1
I0713 17:35:54.952925  6493 net.cpp:150] Setting up conv2_1
I0713 17:35:54.952944  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.952950  6493 net.cpp:165] Memory required for data: 566525952
I0713 17:35:54.952967  6493 layer_factory.hpp:77] Creating layer relu2_1
I0713 17:35:54.952981  6493 net.cpp:100] Creating Layer relu2_1
I0713 17:35:54.952991  6493 net.cpp:434] relu2_1 <- conv2_1
I0713 17:35:54.953001  6493 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0713 17:35:54.953014  6493 net.cpp:150] Setting up relu2_1
I0713 17:35:54.953023  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.953029  6493 net.cpp:165] Memory required for data: 625508352
I0713 17:35:54.953037  6493 layer_factory.hpp:77] Creating layer conv2_2
I0713 17:35:54.953052  6493 net.cpp:100] Creating Layer conv2_2
I0713 17:35:54.953058  6493 net.cpp:434] conv2_2 <- conv2_1
I0713 17:35:54.953070  6493 net.cpp:408] conv2_2 -> conv2_2
I0713 17:35:54.955559  6493 net.cpp:150] Setting up conv2_2
I0713 17:35:54.955581  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.955590  6493 net.cpp:165] Memory required for data: 684490752
I0713 17:35:54.955601  6493 layer_factory.hpp:77] Creating layer relu2_2
I0713 17:35:54.955657  6493 net.cpp:100] Creating Layer relu2_2
I0713 17:35:54.955665  6493 net.cpp:434] relu2_2 <- conv2_2
I0713 17:35:54.955675  6493 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0713 17:35:54.955688  6493 net.cpp:150] Setting up relu2_2
I0713 17:35:54.955698  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.955704  6493 net.cpp:165] Memory required for data: 743473152
I0713 17:35:54.955710  6493 layer_factory.hpp:77] Creating layer pool2
I0713 17:35:54.955721  6493 net.cpp:100] Creating Layer pool2
I0713 17:35:54.955729  6493 net.cpp:434] pool2 <- conv2_2
I0713 17:35:54.955739  6493 net.cpp:408] pool2 -> pool2
I0713 17:35:54.960677  6493 net.cpp:150] Setting up pool2
I0713 17:35:54.960741  6493 net.cpp:157] Top shape: 2 128 120 120 (3686400)
I0713 17:35:54.960750  6493 net.cpp:165] Memory required for data: 758218752
I0713 17:35:54.960762  6493 layer_factory.hpp:77] Creating layer conv3_1
I0713 17:35:54.960796  6493 net.cpp:100] Creating Layer conv3_1
I0713 17:35:54.960806  6493 net.cpp:434] conv3_1 <- pool2
I0713 17:35:54.960827  6493 net.cpp:408] conv3_1 -> conv3_1
I0713 17:35:54.962494  6493 net.cpp:150] Setting up conv3_1
I0713 17:35:54.962534  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.962543  6493 net.cpp:165] Memory required for data: 787709952
I0713 17:35:54.962564  6493 layer_factory.hpp:77] Creating layer relu3_1
I0713 17:35:54.962582  6493 net.cpp:100] Creating Layer relu3_1
I0713 17:35:54.962599  6493 net.cpp:434] relu3_1 <- conv3_1
I0713 17:35:54.962610  6493 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0713 17:35:54.962625  6493 net.cpp:150] Setting up relu3_1
I0713 17:35:54.962635  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.962641  6493 net.cpp:165] Memory required for data: 817201152
I0713 17:35:54.962647  6493 layer_factory.hpp:77] Creating layer conv3_2
I0713 17:35:54.962663  6493 net.cpp:100] Creating Layer conv3_2
I0713 17:35:54.962671  6493 net.cpp:434] conv3_2 <- conv3_1
I0713 17:35:54.962682  6493 net.cpp:408] conv3_2 -> conv3_2
I0713 17:35:54.965714  6493 net.cpp:150] Setting up conv3_2
I0713 17:35:54.965754  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.965760  6493 net.cpp:165] Memory required for data: 846692352
I0713 17:35:54.965777  6493 layer_factory.hpp:77] Creating layer relu3_2
I0713 17:35:54.965808  6493 net.cpp:100] Creating Layer relu3_2
I0713 17:35:54.965816  6493 net.cpp:434] relu3_2 <- conv3_2
I0713 17:35:54.965831  6493 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0713 17:35:54.965848  6493 net.cpp:150] Setting up relu3_2
I0713 17:35:54.965857  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.965863  6493 net.cpp:165] Memory required for data: 876183552
I0713 17:35:54.965870  6493 layer_factory.hpp:77] Creating layer conv3_3
I0713 17:35:54.965888  6493 net.cpp:100] Creating Layer conv3_3
I0713 17:35:54.965908  6493 net.cpp:434] conv3_3 <- conv3_2
I0713 17:35:54.965919  6493 net.cpp:408] conv3_3 -> conv3_3
I0713 17:35:54.968118  6493 net.cpp:150] Setting up conv3_3
I0713 17:35:54.968150  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.968158  6493 net.cpp:165] Memory required for data: 905674752
I0713 17:35:54.968171  6493 layer_factory.hpp:77] Creating layer relu3_3
I0713 17:35:54.968192  6493 net.cpp:100] Creating Layer relu3_3
I0713 17:35:54.968201  6493 net.cpp:434] relu3_3 <- conv3_3
I0713 17:35:54.968219  6493 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0713 17:35:54.968231  6493 net.cpp:150] Setting up relu3_3
I0713 17:35:54.968240  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.968247  6493 net.cpp:165] Memory required for data: 935165952
I0713 17:35:54.968255  6493 layer_factory.hpp:77] Creating layer pool3
I0713 17:35:54.968267  6493 net.cpp:100] Creating Layer pool3
I0713 17:35:54.968274  6493 net.cpp:434] pool3 <- conv3_3
I0713 17:35:54.968286  6493 net.cpp:408] pool3 -> pool3
I0713 17:35:54.968348  6493 net.cpp:150] Setting up pool3
I0713 17:35:54.968369  6493 net.cpp:157] Top shape: 2 256 60 60 (1843200)
I0713 17:35:54.968420  6493 net.cpp:165] Memory required for data: 942538752
I0713 17:35:54.968431  6493 layer_factory.hpp:77] Creating layer conv4_1
I0713 17:35:54.968447  6493 net.cpp:100] Creating Layer conv4_1
I0713 17:35:54.968454  6493 net.cpp:434] conv4_1 <- pool3
I0713 17:35:54.968466  6493 net.cpp:408] conv4_1 -> conv4_1
I0713 17:35:54.972681  6493 net.cpp:150] Setting up conv4_1
I0713 17:35:54.972781  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.972798  6493 net.cpp:165] Memory required for data: 957284352
I0713 17:35:54.972815  6493 layer_factory.hpp:77] Creating layer relu4_1
I0713 17:35:54.972837  6493 net.cpp:100] Creating Layer relu4_1
I0713 17:35:54.972851  6493 net.cpp:434] relu4_1 <- conv4_1
I0713 17:35:54.972867  6493 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0713 17:35:54.972887  6493 net.cpp:150] Setting up relu4_1
I0713 17:35:54.972898  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.972904  6493 net.cpp:165] Memory required for data: 972029952
I0713 17:35:54.972911  6493 layer_factory.hpp:77] Creating layer conv4_2
I0713 17:35:54.972929  6493 net.cpp:100] Creating Layer conv4_2
I0713 17:35:54.972939  6493 net.cpp:434] conv4_2 <- conv4_1
I0713 17:35:54.972951  6493 net.cpp:408] conv4_2 -> conv4_2
I0713 17:35:54.981009  6493 net.cpp:150] Setting up conv4_2
I0713 17:35:54.981060  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.981068  6493 net.cpp:165] Memory required for data: 986775552
I0713 17:35:54.981097  6493 layer_factory.hpp:77] Creating layer relu4_2
I0713 17:35:54.981127  6493 net.cpp:100] Creating Layer relu4_2
I0713 17:35:54.981137  6493 net.cpp:434] relu4_2 <- conv4_2
I0713 17:35:54.981153  6493 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0713 17:35:54.981173  6493 net.cpp:150] Setting up relu4_2
I0713 17:35:54.981181  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.981187  6493 net.cpp:165] Memory required for data: 1001521152
I0713 17:35:54.981195  6493 layer_factory.hpp:77] Creating layer conv4_3
I0713 17:35:54.981211  6493 net.cpp:100] Creating Layer conv4_3
I0713 17:35:54.981225  6493 net.cpp:434] conv4_3 <- conv4_2
I0713 17:35:54.981236  6493 net.cpp:408] conv4_3 -> conv4_3
I0713 17:35:54.989471  6493 net.cpp:150] Setting up conv4_3
I0713 17:35:54.989553  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989562  6493 net.cpp:165] Memory required for data: 1016266752
I0713 17:35:54.989580  6493 layer_factory.hpp:77] Creating layer relu4_3
I0713 17:35:54.989610  6493 net.cpp:100] Creating Layer relu4_3
I0713 17:35:54.989621  6493 net.cpp:434] relu4_3 <- conv4_3
I0713 17:35:54.989637  6493 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0713 17:35:54.989656  6493 net.cpp:150] Setting up relu4_3
I0713 17:35:54.989665  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989672  6493 net.cpp:165] Memory required for data: 1031012352
I0713 17:35:54.989680  6493 layer_factory.hpp:77] Creating layer pool4
I0713 17:35:54.989694  6493 net.cpp:100] Creating Layer pool4
I0713 17:35:54.989707  6493 net.cpp:434] pool4 <- conv4_3
I0713 17:35:54.989718  6493 net.cpp:408] pool4 -> pool4
I0713 17:35:54.989783  6493 net.cpp:150] Setting up pool4
I0713 17:35:54.989800  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989807  6493 net.cpp:165] Memory required for data: 1045757952
I0713 17:35:54.989814  6493 layer_factory.hpp:77] Creating layer conv5_1
I0713 17:35:54.989835  6493 net.cpp:100] Creating Layer conv5_1
I0713 17:35:54.989843  6493 net.cpp:434] conv5_1 <- pool4
I0713 17:35:54.989863  6493 net.cpp:408] conv5_1 -> conv5_1
I0713 17:35:54.998775  6493 net.cpp:150] Setting up conv5_1
I0713 17:35:54.998854  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.998863  6493 net.cpp:165] Memory required for data: 1060503552
I0713 17:35:54.998883  6493 layer_factory.hpp:77] Creating layer relu5_1
I0713 17:35:54.998914  6493 net.cpp:100] Creating Layer relu5_1
I0713 17:35:54.998924  6493 net.cpp:434] relu5_1 <- conv5_1
I0713 17:35:54.998939  6493 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0713 17:35:54.999009  6493 net.cpp:150] Setting up relu5_1
I0713 17:35:54.999020  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.999027  6493 net.cpp:165] Memory required for data: 1075249152
I0713 17:35:54.999033  6493 layer_factory.hpp:77] Creating layer conv5_2
I0713 17:35:54.999052  6493 net.cpp:100] Creating Layer conv5_2
I0713 17:35:54.999058  6493 net.cpp:434] conv5_2 <- conv5_1
I0713 17:35:54.999070  6493 net.cpp:408] conv5_2 -> conv5_2
I0713 17:35:55.007140  6493 net.cpp:150] Setting up conv5_2
I0713 17:35:55.007212  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.007220  6493 net.cpp:165] Memory required for data: 1089994752
I0713 17:35:55.007238  6493 layer_factory.hpp:77] Creating layer relu5_2
I0713 17:35:55.007259  6493 net.cpp:100] Creating Layer relu5_2
I0713 17:35:55.007271  6493 net.cpp:434] relu5_2 <- conv5_2
I0713 17:35:55.007287  6493 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0713 17:35:55.007308  6493 net.cpp:150] Setting up relu5_2
I0713 17:35:55.007319  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.007326  6493 net.cpp:165] Memory required for data: 1104740352
I0713 17:35:55.007333  6493 layer_factory.hpp:77] Creating layer conv5_3
I0713 17:35:55.007350  6493 net.cpp:100] Creating Layer conv5_3
I0713 17:35:55.007359  6493 net.cpp:434] conv5_3 <- conv5_2
I0713 17:35:55.007372  6493 net.cpp:408] conv5_3 -> conv5_3
I0713 17:35:55.015444  6493 net.cpp:150] Setting up conv5_3
I0713 17:35:55.015511  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015519  6493 net.cpp:165] Memory required for data: 1119485952
I0713 17:35:55.015537  6493 layer_factory.hpp:77] Creating layer relu5_3
I0713 17:35:55.015558  6493 net.cpp:100] Creating Layer relu5_3
I0713 17:35:55.015568  6493 net.cpp:434] relu5_3 <- conv5_3
I0713 17:35:55.015584  6493 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0713 17:35:55.015604  6493 net.cpp:150] Setting up relu5_3
I0713 17:35:55.015612  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015619  6493 net.cpp:165] Memory required for data: 1134231552
I0713 17:35:55.015626  6493 layer_factory.hpp:77] Creating layer pool5
I0713 17:35:55.015640  6493 net.cpp:100] Creating Layer pool5
I0713 17:35:55.015653  6493 net.cpp:434] pool5 <- conv5_3
I0713 17:35:55.015664  6493 net.cpp:408] pool5 -> pool5
I0713 17:35:55.015730  6493 net.cpp:150] Setting up pool5
I0713 17:35:55.015744  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015751  6493 net.cpp:165] Memory required for data: 1148977152
I0713 17:35:55.015758  6493 layer_factory.hpp:77] Creating layer pool5a
I0713 17:35:55.015779  6493 net.cpp:100] Creating Layer pool5a
I0713 17:35:55.015786  6493 net.cpp:434] pool5a <- pool5
I0713 17:35:55.015797  6493 net.cpp:408] pool5a -> pool5a
I0713 17:35:55.015835  6493 net.cpp:150] Setting up pool5a
I0713 17:35:55.015847  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015854  6493 net.cpp:165] Memory required for data: 1163722752
I0713 17:35:55.015861  6493 layer_factory.hpp:77] Creating layer fc6-conv
I0713 17:35:55.015879  6493 net.cpp:100] Creating Layer fc6-conv
I0713 17:35:55.015887  6493 net.cpp:434] fc6-conv <- pool5a
I0713 17:35:55.015898  6493 net.cpp:408] fc6-conv -> fc6-conv
I0713 17:35:55.333092  6493 net.cpp:150] Setting up fc6-conv
I0713 17:35:55.333170  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333179  6493 net.cpp:165] Memory required for data: 1206190080
I0713 17:35:55.333223  6493 layer_factory.hpp:77] Creating layer relu6
I0713 17:35:55.333284  6493 net.cpp:100] Creating Layer relu6
I0713 17:35:55.333317  6493 net.cpp:434] relu6 <- fc6-conv
I0713 17:35:55.333334  6493 net.cpp:395] relu6 -> fc6-conv (in-place)
I0713 17:35:55.333353  6493 net.cpp:150] Setting up relu6
I0713 17:35:55.333361  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333369  6493 net.cpp:165] Memory required for data: 1248657408
I0713 17:35:55.333374  6493 layer_factory.hpp:77] Creating layer drop6
I0713 17:35:55.333395  6493 net.cpp:100] Creating Layer drop6
I0713 17:35:55.333431  6493 net.cpp:434] drop6 <- fc6-conv
I0713 17:35:55.333442  6493 net.cpp:395] drop6 -> fc6-conv (in-place)
I0713 17:35:55.333487  6493 net.cpp:150] Setting up drop6
I0713 17:35:55.333501  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333508  6493 net.cpp:165] Memory required for data: 1291124736
I0713 17:35:55.333515  6493 layer_factory.hpp:77] Creating layer fc7-conv
I0713 17:35:55.333545  6493 net.cpp:100] Creating Layer fc7-conv
I0713 17:35:55.333554  6493 net.cpp:434] fc7-conv <- fc6-conv
I0713 17:35:55.333564  6493 net.cpp:408] fc7-conv -> fc7-conv
I0713 17:35:55.383952  6493 net.cpp:150] Setting up fc7-conv
I0713 17:35:55.384017  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384027  6493 net.cpp:165] Memory required for data: 1333592064
I0713 17:35:55.384043  6493 layer_factory.hpp:77] Creating layer relu7
I0713 17:35:55.384080  6493 net.cpp:100] Creating Layer relu7
I0713 17:35:55.384091  6493 net.cpp:434] relu7 <- fc7-conv
I0713 17:35:55.384106  6493 net.cpp:395] relu7 -> fc7-conv (in-place)
I0713 17:35:55.384124  6493 net.cpp:150] Setting up relu7
I0713 17:35:55.384133  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384140  6493 net.cpp:165] Memory required for data: 1376059392
I0713 17:35:55.384146  6493 layer_factory.hpp:77] Creating layer drop7
I0713 17:35:55.384166  6493 net.cpp:100] Creating Layer drop7
I0713 17:35:55.384174  6493 net.cpp:434] drop7 <- fc7-conv
I0713 17:35:55.384184  6493 net.cpp:395] drop7 -> fc7-conv (in-place)
I0713 17:35:55.384227  6493 net.cpp:150] Setting up drop7
I0713 17:35:55.384239  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384246  6493 net.cpp:165] Memory required for data: 1418526720
I0713 17:35:55.384253  6493 layer_factory.hpp:77] Creating layer fc8-VOC
I0713 17:35:55.384271  6493 net.cpp:100] Creating Layer fc8-VOC
I0713 17:35:55.384279  6493 net.cpp:434] fc8-VOC <- fc7-conv
I0713 17:35:55.384294  6493 net.cpp:408] fc8-VOC -> fc8-VOC
I0713 17:35:55.388170  6493 net.cpp:150] Setting up fc8-VOC
I0713 17:35:55.388190  6493 net.cpp:157] Top shape: 2 21 36 36 (54432)
I0713 17:35:55.388197  6493 net.cpp:165] Memory required for data: 1418744448
I0713 17:35:55.388209  6493 layer_factory.hpp:77] Creating layer upscore2
I0713 17:35:55.388223  6493 net.cpp:100] Creating Layer upscore2
I0713 17:35:55.388231  6493 net.cpp:434] upscore2 <- fc8-VOC
I0713 17:35:55.388242  6493 net.cpp:408] upscore2 -> upscore
I0713 17:35:55.388895  6493 net.cpp:150] Setting up upscore2
I0713 17:35:55.388912  6493 net.cpp:157] Top shape: 2 21 288 288 (3483648)
I0713 17:35:55.388919  6493 net.cpp:165] Memory required for data: 1432679040
I0713 17:35:55.388947  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:55.388975  6493 net.cpp:100] Creating Layer loss
I0713 17:35:55.388988  6493 net.cpp:434] loss <- upscore
I0713 17:35:55.388996  6493 net.cpp:434] loss <- label
I0713 17:35:55.389008  6493 net.cpp:408] loss -> loss
I0713 17:35:55.389024  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:55.400105  6493 net.cpp:150] Setting up loss
I0713 17:35:55.400159  6493 net.cpp:157] Top shape: (1)
I0713 17:35:55.400167  6493 net.cpp:160]     with loss weight 1
I0713 17:35:55.400223  6493 net.cpp:165] Memory required for data: 1432679044
I0713 17:35:55.400235  6493 net.cpp:226] loss needs backward computation.
I0713 17:35:55.400244  6493 net.cpp:226] upscore2 needs backward computation.
I0713 17:35:55.400252  6493 net.cpp:226] fc8-VOC needs backward computation.
I0713 17:35:55.400259  6493 net.cpp:226] drop7 needs backward computation.
I0713 17:35:55.400265  6493 net.cpp:226] relu7 needs backward computation.
I0713 17:35:55.400272  6493 net.cpp:226] fc7-conv needs backward computation.
I0713 17:35:55.400279  6493 net.cpp:226] drop6 needs backward computation.
I0713 17:35:55.400285  6493 net.cpp:226] relu6 needs backward computation.
I0713 17:35:55.400291  6493 net.cpp:226] fc6-conv needs backward computation.
I0713 17:35:55.400298  6493 net.cpp:226] pool5a needs backward computation.
I0713 17:35:55.400342  6493 net.cpp:226] pool5 needs backward computation.
I0713 17:35:55.400352  6493 net.cpp:226] relu5_3 needs backward computation.
I0713 17:35:55.400359  6493 net.cpp:226] conv5_3 needs backward computation.
I0713 17:35:55.400367  6493 net.cpp:226] relu5_2 needs backward computation.
I0713 17:35:55.400382  6493 net.cpp:226] conv5_2 needs backward computation.
I0713 17:35:55.400388  6493 net.cpp:226] relu5_1 needs backward computation.
I0713 17:35:55.400404  6493 net.cpp:226] conv5_1 needs backward computation.
I0713 17:35:55.400419  6493 net.cpp:226] pool4 needs backward computation.
I0713 17:35:55.400426  6493 net.cpp:226] relu4_3 needs backward computation.
I0713 17:35:55.400434  6493 net.cpp:226] conv4_3 needs backward computation.
I0713 17:35:55.400440  6493 net.cpp:226] relu4_2 needs backward computation.
I0713 17:35:55.400447  6493 net.cpp:226] conv4_2 needs backward computation.
I0713 17:35:55.400454  6493 net.cpp:226] relu4_1 needs backward computation.
I0713 17:35:55.400460  6493 net.cpp:226] conv4_1 needs backward computation.
I0713 17:35:55.400466  6493 net.cpp:226] pool3 needs backward computation.
I0713 17:35:55.400473  6493 net.cpp:226] relu3_3 needs backward computation.
I0713 17:35:55.400480  6493 net.cpp:226] conv3_3 needs backward computation.
I0713 17:35:55.400485  6493 net.cpp:226] relu3_2 needs backward computation.
I0713 17:35:55.400491  6493 net.cpp:226] conv3_2 needs backward computation.
I0713 17:35:55.400498  6493 net.cpp:226] relu3_1 needs backward computation.
I0713 17:35:55.400506  6493 net.cpp:226] conv3_1 needs backward computation.
I0713 17:35:55.400512  6493 net.cpp:226] pool2 needs backward computation.
I0713 17:35:55.400518  6493 net.cpp:226] relu2_2 needs backward computation.
I0713 17:35:55.400526  6493 net.cpp:226] conv2_2 needs backward computation.
I0713 17:35:55.400532  6493 net.cpp:226] relu2_1 needs backward computation.
I0713 17:35:55.400538  6493 net.cpp:226] conv2_1 needs backward computation.
I0713 17:35:55.400558  6493 net.cpp:226] pool1 needs backward computation.
I0713 17:35:55.400566  6493 net.cpp:226] relu1_2 needs backward computation.
I0713 17:35:55.400573  6493 net.cpp:226] conv1_2 needs backward computation.
I0713 17:35:55.400578  6493 net.cpp:226] relu1_1 needs backward computation.
I0713 17:35:55.400588  6493 net.cpp:226] conv1_1 needs backward computation.
I0713 17:35:55.400595  6493 net.cpp:228] data does not need backward computation.
I0713 17:35:55.400601  6493 net.cpp:270] This network produces output loss
I0713 17:35:55.400640  6493 net.cpp:283] Network initialization done.
I0713 17:35:55.401125  6493 solver.cpp:63] Solver scaffolding done.
I0713 17:35:55.507159  6493 solver.cpp:68] Pavi init done.
I0713 17:35:55.509263  6493 caffe.cpp:155] Finetuning from examples/DPN_VOC/VGG_16.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537843972
I0713 17:35:56.714289  6493 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/DPN_VOC/VGG_16.caffemodel
I0713 17:35:56.714351  6493 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0713 17:35:56.714361  6493 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0713 17:35:56.722481  6493 net.cpp:761] Ignoring source layer split4
I0713 17:35:56.724892  6493 net.cpp:761] Ignoring source layer relu5_1_1
I0713 17:35:56.724952  6493 net.cpp:761] Ignoring source layer relu5_1_2
I0713 17:35:56.724959  6493 net.cpp:761] Ignoring source layer relu5_1_3
I0713 17:35:56.724966  6493 net.cpp:761] Ignoring source layer relu5_1_4
I0713 17:35:56.727246  6493 net.cpp:761] Ignoring source layer relu5_2_1
I0713 17:35:56.727309  6493 net.cpp:761] Ignoring source layer relu5_2_2
I0713 17:35:56.727316  6493 net.cpp:761] Ignoring source layer relu5_2_3
I0713 17:35:56.727322  6493 net.cpp:761] Ignoring source layer relu5_2_4
I0713 17:35:56.729638  6493 net.cpp:761] Ignoring source layer relu5_3_1
I0713 17:35:56.729698  6493 net.cpp:761] Ignoring source layer relu5_3_2
I0713 17:35:56.729704  6493 net.cpp:761] Ignoring source layer relu5_3_3
I0713 17:35:56.729764  6493 net.cpp:761] Ignoring source layer relu5_3_4
I0713 17:35:56.729773  6493 net.cpp:761] Ignoring source layer split5_1
I0713 17:35:56.729779  6493 net.cpp:761] Ignoring source layer split5_2
I0713 17:35:56.729790  6493 net.cpp:761] Ignoring source layer split5_3
I0713 17:35:56.729797  6493 net.cpp:761] Ignoring source layer split5_4
I0713 17:35:56.855729  6493 net.cpp:761] Ignoring source layer relu6_1
I0713 17:35:56.855787  6493 net.cpp:761] Ignoring source layer relu6_2
I0713 17:35:56.855795  6493 net.cpp:761] Ignoring source layer relu6_3
I0713 17:35:56.855801  6493 net.cpp:761] Ignoring source layer relu6_4
I0713 17:35:56.855808  6493 net.cpp:761] Ignoring source layer relu6_5
I0713 17:35:56.855813  6493 net.cpp:761] Ignoring source layer relu6_6
I0713 17:35:56.855819  6493 net.cpp:761] Ignoring source layer relu6_7
I0713 17:35:56.855825  6493 net.cpp:761] Ignoring source layer relu6_8
I0713 17:35:56.855830  6493 net.cpp:761] Ignoring source layer relu6_9
I0713 17:35:56.855841  6493 net.cpp:761] Ignoring source layer relu6_10
I0713 17:35:56.855852  6493 net.cpp:761] Ignoring source layer relu6_11
I0713 17:35:56.855859  6493 net.cpp:761] Ignoring source layer relu6_12
I0713 17:35:56.855864  6493 net.cpp:761] Ignoring source layer relu6_13
I0713 17:35:56.855870  6493 net.cpp:761] Ignoring source layer relu6_14
I0713 17:35:56.855875  6493 net.cpp:761] Ignoring source layer relu6_15
I0713 17:35:56.855880  6493 net.cpp:761] Ignoring source layer relu6_16
I0713 17:35:56.877863  6493 net.cpp:761] Ignoring source layer relu7_1
I0713 17:35:56.877907  6493 net.cpp:761] Ignoring source layer relu7_2
I0713 17:35:56.877913  6493 net.cpp:761] Ignoring source layer relu7_3
I0713 17:35:56.877919  6493 net.cpp:761] Ignoring source layer relu7_4
I0713 17:35:56.877925  6493 net.cpp:761] Ignoring source layer relu7_5
I0713 17:35:56.877931  6493 net.cpp:761] Ignoring source layer relu7_6
I0713 17:35:56.877938  6493 net.cpp:761] Ignoring source layer relu7_7
I0713 17:35:56.877943  6493 net.cpp:761] Ignoring source layer relu7_8
I0713 17:35:56.877948  6493 net.cpp:761] Ignoring source layer relu7_9
I0713 17:35:56.877955  6493 net.cpp:761] Ignoring source layer relu7_10
I0713 17:35:56.877961  6493 net.cpp:761] Ignoring source layer relu7_11
I0713 17:35:56.877970  6493 net.cpp:761] Ignoring source layer relu7_12
I0713 17:35:56.877975  6493 net.cpp:761] Ignoring source layer relu7_13
I0713 17:35:56.877981  6493 net.cpp:761] Ignoring source layer relu7_14
I0713 17:35:56.877986  6493 net.cpp:761] Ignoring source layer relu7_15
I0713 17:35:56.877991  6493 net.cpp:761] Ignoring source layer relu7_16
I0713 17:35:56.877997  6493 net.cpp:761] Ignoring source layer fc8-conv_21
I0713 17:35:56.878003  6493 net.cpp:761] Ignoring source layer split6
I0713 17:35:56.878010  6493 net.cpp:761] Ignoring source layer upscore
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537843972
I0713 17:35:58.069021  6493 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/DPN_VOC/VGG_16.caffemodel
I0713 17:35:58.069077  6493 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0713 17:35:58.069084  6493 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0713 17:35:58.085005  6493 net.cpp:761] Ignoring source layer split4
I0713 17:35:58.088013  6493 net.cpp:761] Ignoring source layer relu5_1_1
I0713 17:35:58.088054  6493 net.cpp:761] Ignoring source layer relu5_1_2
I0713 17:35:58.088063  6493 net.cpp:761] Ignoring source layer relu5_1_3
I0713 17:35:58.088069  6493 net.cpp:761] Ignoring source layer relu5_1_4
I0713 17:35:58.091111  6493 net.cpp:761] Ignoring source layer relu5_2_1
I0713 17:35:58.091153  6493 net.cpp:761] Ignoring source layer relu5_2_2
I0713 17:35:58.091161  6493 net.cpp:761] Ignoring source layer relu5_2_3
I0713 17:35:58.091166  6493 net.cpp:761] Ignoring source layer relu5_2_4
I0713 17:35:58.094200  6493 net.cpp:761] Ignoring source layer relu5_3_1
I0713 17:35:58.094238  6493 net.cpp:761] Ignoring source layer relu5_3_2
I0713 17:35:58.094287  6493 net.cpp:761] Ignoring source layer relu5_3_3
I0713 17:35:58.094295  6493 net.cpp:761] Ignoring source layer relu5_3_4
I0713 17:35:58.094301  6493 net.cpp:761] Ignoring source layer split5_1
I0713 17:35:58.094307  6493 net.cpp:761] Ignoring source layer split5_2
I0713 17:35:58.094312  6493 net.cpp:761] Ignoring source layer split5_3
I0713 17:35:58.094323  6493 net.cpp:761] Ignoring source layer split5_4
I0713 17:35:58.209172  6493 net.cpp:761] Ignoring source layer relu6_1
I0713 17:35:58.209236  6493 net.cpp:761] Ignoring source layer relu6_2
I0713 17:35:58.209245  6493 net.cpp:761] Ignoring source layer relu6_3
I0713 17:35:58.209251  6493 net.cpp:761] Ignoring source layer relu6_4
I0713 17:35:58.209257  6493 net.cpp:761] Ignoring source layer relu6_5
I0713 17:35:58.209264  6493 net.cpp:761] Ignoring source layer relu6_6
I0713 17:35:58.209270  6493 net.cpp:761] Ignoring source layer relu6_7
I0713 17:35:58.209276  6493 net.cpp:761] Ignoring source layer relu6_8
I0713 17:35:58.209282  6493 net.cpp:761] Ignoring source layer relu6_9
I0713 17:35:58.209288  6493 net.cpp:761] Ignoring source layer relu6_10
I0713 17:35:58.209295  6493 net.cpp:761] Ignoring source layer relu6_11
I0713 17:35:58.209300  6493 net.cpp:761] Ignoring source layer relu6_12
I0713 17:35:58.209306  6493 net.cpp:761] Ignoring source layer relu6_13
I0713 17:35:58.209311  6493 net.cpp:761] Ignoring source layer relu6_14
I0713 17:35:58.209317  6493 net.cpp:761] Ignoring source layer relu6_15
I0713 17:35:58.209322  6493 net.cpp:761] Ignoring source layer relu6_16
I0713 17:35:58.228015  6493 net.cpp:761] Ignoring source layer relu7_1
I0713 17:35:58.228063  6493 net.cpp:761] Ignoring source layer relu7_2
I0713 17:35:58.228070  6493 net.cpp:761] Ignoring source layer relu7_3
I0713 17:35:58.228077  6493 net.cpp:761] Ignoring source layer relu7_4
I0713 17:35:58.228083  6493 net.cpp:761] Ignoring source layer relu7_5
I0713 17:35:58.228090  6493 net.cpp:761] Ignoring source layer relu7_6
I0713 17:35:58.228097  6493 net.cpp:761] Ignoring source layer relu7_7
I0713 17:35:58.228103  6493 net.cpp:761] Ignoring source layer relu7_8
I0713 17:35:58.228111  6493 net.cpp:761] Ignoring source layer relu7_9
I0713 17:35:58.228116  6493 net.cpp:761] Ignoring source layer relu7_10
I0713 17:35:58.228121  6493 net.cpp:761] Ignoring source layer relu7_11
I0713 17:35:58.228127  6493 net.cpp:761] Ignoring source layer relu7_12
I0713 17:35:58.228133  6493 net.cpp:761] Ignoring source layer relu7_13
I0713 17:35:58.228139  6493 net.cpp:761] Ignoring source layer relu7_14
I0713 17:35:58.228145  6493 net.cpp:761] Ignoring source layer relu7_15
I0713 17:35:58.228150  6493 net.cpp:761] Ignoring source layer relu7_16
I0713 17:35:58.228157  6493 net.cpp:761] Ignoring source layer fc8-conv_21
I0713 17:35:58.228163  6493 net.cpp:761] Ignoring source layer split6
I0713 17:35:58.228169  6493 net.cpp:761] Ignoring source layer upscore
I0713 17:35:58.233036  6493 caffe.cpp:251] Starting Optimization
I0713 17:35:58.233086  6493 solver.cpp:294] Solving DPN
I0713 17:35:58.233096  6493 solver.cpp:295] Learning Rate Policy: step
I0713 17:35:58.237236  6493 solver.cpp:352] Iteration 0, Testing net (#0)
I0713 17:39:08.359921  6493 solver.cpp:419]     Test net output #0: loss = 3.81606 (* 1 = 3.81606 loss)
I0713 17:39:09.793334  6493 solver.cpp:235] Iteration 0, loss = 4.13121
I0713 17:39:09.793568  6493 solver.cpp:255]     Train net output #0: loss = 4.13121 (* 1 = 4.13121 loss)
I0713 17:39:09.793853  6493 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0713 17:39:57.378682  6493 solver.cpp:235] Iteration 10, loss = 2.56187
I0713 17:39:57.379040  6493 solver.cpp:255]     Train net output #0: loss = 2.56187 (* 1 = 2.56187 loss)
I0713 17:39:57.379323  6493 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0713 17:40:44.975020  6493 solver.cpp:235] Iteration 20, loss = 2.35665
I0713 17:40:44.975419  6493 solver.cpp:255]     Train net output #0: loss = 2.35665 (* 1 = 2.35665 loss)
I0713 17:40:44.975664  6493 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0713 17:41:32.499617  6493 solver.cpp:235] Iteration 30, loss = 1.88635
I0713 17:41:32.499909  6493 solver.cpp:255]     Train net output #0: loss = 1.88635 (* 1 = 1.88635 loss)
I0713 17:41:32.500028  6493 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0713 17:42:20.059455  6493 solver.cpp:235] Iteration 40, loss = 1.29347
I0713 17:42:20.059921  6493 solver.cpp:255]     Train net output #0: loss = 1.29347 (* 1 = 1.29347 loss)
I0713 17:42:20.060201  6493 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0713 17:43:07.612068  6493 solver.cpp:235] Iteration 50, loss = 1.16835
I0713 17:43:07.612412  6493 solver.cpp:255]     Train net output #0: loss = 1.16835 (* 1 = 1.16835 loss)
I0713 17:43:07.612689  6493 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0713 17:43:55.216481  6493 solver.cpp:235] Iteration 60, loss = 1.06255
I0713 17:43:55.216944  6493 solver.cpp:255]     Train net output #0: loss = 1.06255 (* 1 = 1.06255 loss)
I0713 17:43:55.217069  6493 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0713 17:44:42.775416  6493 solver.cpp:235] Iteration 70, loss = 1.47292
I0713 17:44:42.775751  6493 solver.cpp:255]     Train net output #0: loss = 1.47292 (* 1 = 1.47292 loss)
I0713 17:44:42.776046  6493 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0713 17:45:30.331249  6493 solver.cpp:235] Iteration 80, loss = 1.68133
I0713 17:45:30.331588  6493 solver.cpp:255]     Train net output #0: loss = 1.68133 (* 1 = 1.68133 loss)
I0713 17:45:30.331723  6493 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0713 17:46:17.926605  6493 solver.cpp:235] Iteration 90, loss = 1.17974
I0713 17:46:17.926947  6493 solver.cpp:255]     Train net output #0: loss = 1.17974 (* 1 = 1.17974 loss)
I0713 17:46:17.927191  6493 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0713 17:47:05.477949  6493 solver.cpp:235] Iteration 100, loss = 1.16226
I0713 17:47:05.478348  6493 solver.cpp:255]     Train net output #0: loss = 1.16226 (* 1 = 1.16226 loss)
I0713 17:47:05.478586  6493 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0713 17:47:53.045765  6493 solver.cpp:235] Iteration 110, loss = 1.28845
I0713 17:47:53.046149  6493 solver.cpp:255]     Train net output #0: loss = 1.28845 (* 1 = 1.28845 loss)
I0713 17:47:53.046439  6493 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0713 17:48:40.596344  6493 solver.cpp:235] Iteration 120, loss = 1.50325
I0713 17:48:40.596663  6493 solver.cpp:255]     Train net output #0: loss = 1.50325 (* 1 = 1.50325 loss)
I0713 17:48:40.596796  6493 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0713 17:49:28.199036  6493 solver.cpp:235] Iteration 130, loss = 1.11058
I0713 17:49:28.199388  6493 solver.cpp:255]     Train net output #0: loss = 1.11058 (* 1 = 1.11058 loss)
I0713 17:49:28.199499  6493 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0713 17:50:15.761621  6493 solver.cpp:235] Iteration 140, loss = 1.79032
I0713 17:50:15.761981  6493 solver.cpp:255]     Train net output #0: loss = 1.79032 (* 1 = 1.79032 loss)
I0713 17:50:15.762085  6493 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0713 17:51:03.338533  6493 solver.cpp:235] Iteration 150, loss = 0.963379
I0713 17:51:03.338871  6493 solver.cpp:255]     Train net output #0: loss = 0.963379 (* 1 = 0.963379 loss)
I0713 17:51:03.339115  6493 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0713 17:51:50.918790  6493 solver.cpp:235] Iteration 160, loss = 1.15879
I0713 17:51:50.919112  6493 solver.cpp:255]     Train net output #0: loss = 1.15879 (* 1 = 1.15879 loss)
I0713 17:51:50.919359  6493 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0713 17:52:38.511404  6493 solver.cpp:235] Iteration 170, loss = 0.866312
I0713 17:52:38.511788  6493 solver.cpp:255]     Train net output #0: loss = 0.866312 (* 1 = 0.866312 loss)
I0713 17:52:38.512061  6493 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0713 17:53:26.079893  6493 solver.cpp:235] Iteration 180, loss = 1.22304
I0713 17:53:26.080282  6493 solver.cpp:255]     Train net output #0: loss = 1.22304 (* 1 = 1.22304 loss)
I0713 17:53:26.080523  6493 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0713 17:54:13.666700  6493 solver.cpp:235] Iteration 190, loss = 1.00456
I0713 17:54:13.667098  6493 solver.cpp:255]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0713 17:54:13.667219  6493 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0713 17:54:56.574578  6493 solver.cpp:352] Iteration 200, Testing net (#0)
I0713 17:58:10.094040  6493 solver.cpp:419]     Test net output #0: loss = 1.30468 (* 1 = 1.30468 loss)
I0713 17:58:11.442456  6493 solver.cpp:235] Iteration 200, loss = 1.65273
I0713 17:58:11.442673  6493 solver.cpp:255]     Train net output #0: loss = 1.65273 (* 1 = 1.65273 loss)
I0713 17:58:11.442821  6493 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0713 17:58:59.025554  6493 solver.cpp:235] Iteration 210, loss = 0.816059
I0713 17:58:59.025943  6493 solver.cpp:255]     Train net output #0: loss = 0.816059 (* 1 = 0.816059 loss)
I0713 17:58:59.026197  6493 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0713 17:59:46.574992  6493 solver.cpp:235] Iteration 220, loss = 1.46234
I0713 17:59:46.575378  6493 solver.cpp:255]     Train net output #0: loss = 1.46234 (* 1 = 1.46234 loss)
I0713 17:59:46.575494  6493 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0713 18:00:34.085682  6493 solver.cpp:235] Iteration 230, loss = 1.09307
I0713 18:00:34.086040  6493 solver.cpp:255]     Train net output #0: loss = 1.09307 (* 1 = 1.09307 loss)
I0713 18:00:34.086156  6493 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0713 18:01:21.682215  6493 solver.cpp:235] Iteration 240, loss = 0.967451
I0713 18:01:21.682674  6493 solver.cpp:255]     Train net output #0: loss = 0.967451 (* 1 = 0.967451 loss)
I0713 18:01:21.682931  6493 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0713 18:02:09.244067  6493 solver.cpp:235] Iteration 250, loss = 1.05817
I0713 18:02:09.244441  6493 solver.cpp:255]     Train net output #0: loss = 1.05817 (* 1 = 1.05817 loss)
I0713 18:02:09.244729  6493 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0713 18:02:56.829264  6493 solver.cpp:235] Iteration 260, loss = 1.5803
I0713 18:02:56.829654  6493 solver.cpp:255]     Train net output #0: loss = 1.5803 (* 1 = 1.5803 loss)
I0713 18:02:56.829766  6493 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0713 18:03:44.398720  6493 solver.cpp:235] Iteration 270, loss = 1.06304
I0713 18:03:44.399153  6493 solver.cpp:255]     Train net output #0: loss = 1.06304 (* 1 = 1.06304 loss)
I0713 18:03:44.399417  6493 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0713 18:04:31.990109  6493 solver.cpp:235] Iteration 280, loss = 0.994219
I0713 18:04:31.990483  6493 solver.cpp:255]     Train net output #0: loss = 0.994219 (* 1 = 0.994219 loss)
I0713 18:04:31.990589  6493 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0713 18:05:19.579196  6493 solver.cpp:235] Iteration 290, loss = 0.798217
I0713 18:05:19.579524  6493 solver.cpp:255]     Train net output #0: loss = 0.798217 (* 1 = 0.798217 loss)
I0713 18:05:19.579644  6493 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0713 18:06:07.129338  6493 solver.cpp:235] Iteration 300, loss = 0.83289
I0713 18:06:07.129665  6493 solver.cpp:255]     Train net output #0: loss = 0.83289 (* 1 = 0.83289 loss)
I0713 18:06:07.129777  6493 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0713 18:06:54.693402  6493 solver.cpp:235] Iteration 310, loss = 1.73084
I0713 18:06:54.693769  6493 solver.cpp:255]     Train net output #0: loss = 1.73084 (* 1 = 1.73084 loss)
I0713 18:06:54.693881  6493 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0713 18:07:42.327157  6493 solver.cpp:235] Iteration 320, loss = 1.20503
I0713 18:07:42.327503  6493 solver.cpp:255]     Train net output #0: loss = 1.20503 (* 1 = 1.20503 loss)
I0713 18:07:42.327767  6493 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0713 18:08:29.926476  6493 solver.cpp:235] Iteration 330, loss = 0.782285
I0713 18:08:29.926916  6493 solver.cpp:255]     Train net output #0: loss = 0.782285 (* 1 = 0.782285 loss)
I0713 18:08:29.927148  6493 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0713 18:09:17.535320  6493 solver.cpp:235] Iteration 340, loss = 1.55006
I0713 18:09:17.535727  6493 solver.cpp:255]     Train net output #0: loss = 1.55006 (* 1 = 1.55006 loss)
I0713 18:09:17.535840  6493 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0713 18:10:05.107610  6493 solver.cpp:235] Iteration 350, loss = 0.883042
I0713 18:10:05.107993  6493 solver.cpp:255]     Train net output #0: loss = 0.883042 (* 1 = 0.883042 loss)
I0713 18:10:05.108100  6493 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0713 18:10:52.709818  6493 solver.cpp:235] Iteration 360, loss = 0.79635
I0713 18:10:52.710187  6493 solver.cpp:255]     Train net output #0: loss = 0.79635 (* 1 = 0.79635 loss)
I0713 18:10:52.710305  6493 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0713 18:11:40.291687  6493 solver.cpp:235] Iteration 370, loss = 0.90753
I0713 18:11:40.292078  6493 solver.cpp:255]     Train net output #0: loss = 0.90753 (* 1 = 0.90753 loss)
I0713 18:11:40.292353  6493 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0713 18:12:27.858803  6493 solver.cpp:235] Iteration 380, loss = 1.10735
I0713 18:12:27.859211  6493 solver.cpp:255]     Train net output #0: loss = 1.10735 (* 1 = 1.10735 loss)
I0713 18:12:27.859498  6493 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0713 18:13:15.453608  6493 solver.cpp:235] Iteration 390, loss = 0.727647
I0713 18:13:15.453943  6493 solver.cpp:255]     Train net output #0: loss = 0.727647 (* 1 = 0.727647 loss)
I0713 18:13:15.454048  6493 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0713 18:13:58.334667  6493 solver.cpp:352] Iteration 400, Testing net (#0)
I0713 18:17:12.130890  6493 solver.cpp:419]     Test net output #0: loss = 1.03492 (* 1 = 1.03492 loss)
I0713 18:17:13.473902  6493 solver.cpp:235] Iteration 400, loss = 1.04547
I0713 18:17:13.474117  6493 solver.cpp:255]     Train net output #0: loss = 1.04547 (* 1 = 1.04547 loss)
I0713 18:17:13.474405  6493 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0713 18:18:01.079958  6493 solver.cpp:235] Iteration 410, loss = 1.1051
I0713 18:18:01.080308  6493 solver.cpp:255]     Train net output #0: loss = 1.1051 (* 1 = 1.1051 loss)
I0713 18:18:01.080567  6493 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0713 18:18:48.632704  6493 solver.cpp:235] Iteration 420, loss = 0.863962
I0713 18:18:48.633162  6493 solver.cpp:255]     Train net output #0: loss = 0.863962 (* 1 = 0.863962 loss)
I0713 18:18:48.633360  6493 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0713 18:19:36.172736  6493 solver.cpp:235] Iteration 430, loss = 1.39345
I0713 18:19:36.173063  6493 solver.cpp:255]     Train net output #0: loss = 1.39345 (* 1 = 1.39345 loss)
I0713 18:19:36.173174  6493 sgd_solver.cpp:106] Iteration 430, lr = 0.001
I0713 18:20:23.757697  6493 solver.cpp:235] Iteration 440, loss = 1.10539
I0713 18:20:23.758121  6493 solver.cpp:255]     Train net output #0: loss = 1.10539 (* 1 = 1.10539 loss)
I0713 18:20:23.758245  6493 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0713 18:21:11.335244  6493 solver.cpp:235] Iteration 450, loss = 0.638902
I0713 18:21:11.335646  6493 solver.cpp:255]     Train net output #0: loss = 0.638902 (* 1 = 0.638902 loss)
I0713 18:21:11.335767  6493 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0713 18:21:58.866410  6493 solver.cpp:235] Iteration 460, loss = 0.706122
I0713 18:21:58.866824  6493 solver.cpp:255]     Train net output #0: loss = 0.706122 (* 1 = 0.706122 loss)
I0713 18:21:58.866936  6493 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0713 18:22:46.397063  6493 solver.cpp:235] Iteration 470, loss = 0.867286
I0713 18:22:46.397418  6493 solver.cpp:255]     Train net output #0: loss = 0.867286 (* 1 = 0.867286 loss)
I0713 18:22:46.397677  6493 sgd_solver.cpp:106] Iteration 470, lr = 0.001
I0713 18:23:33.977047  6493 solver.cpp:235] Iteration 480, loss = 1.28761
I0713 18:23:33.977397  6493 solver.cpp:255]     Train net output #0: loss = 1.28761 (* 1 = 1.28761 loss)
I0713 18:23:33.977681  6493 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0713 18:24:21.582332  6493 solver.cpp:235] Iteration 490, loss = 0.788717
I0713 18:24:21.582721  6493 solver.cpp:255]     Train net output #0: loss = 0.788717 (* 1 = 0.788717 loss)
I0713 18:24:21.582837  6493 sgd_solver.cpp:106] Iteration 490, lr = 0.001
I0713 18:25:09.156677  6493 solver.cpp:235] Iteration 500, loss = 1.95718
I0713 18:25:09.157160  6493 solver.cpp:255]     Train net output #0: loss = 1.95718 (* 1 = 1.95718 loss)
I0713 18:25:09.157299  6493 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0713 18:25:56.718302  6493 solver.cpp:235] Iteration 510, loss = 1.45485
I0713 18:25:56.718718  6493 solver.cpp:255]     Train net output #0: loss = 1.45485 (* 1 = 1.45485 loss)
I0713 18:25:56.718962  6493 sgd_solver.cpp:106] Iteration 510, lr = 0.001
I0713 18:26:44.295348  6493 solver.cpp:235] Iteration 520, loss = 1.2503
I0713 18:26:44.295775  6493 solver.cpp:255]     Train net output #0: loss = 1.2503 (* 1 = 1.2503 loss)
I0713 18:26:44.296005  6493 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0713 18:27:31.914217  6493 solver.cpp:235] Iteration 530, loss = 1.22893
I0713 18:27:31.914577  6493 solver.cpp:255]     Train net output #0: loss = 1.22893 (* 1 = 1.22893 loss)
I0713 18:27:31.914821  6493 sgd_solver.cpp:106] Iteration 530, lr = 0.001
I0713 18:28:19.486292  6493 solver.cpp:235] Iteration 540, loss = 1.63879
I0713 18:28:19.486729  6493 solver.cpp:255]     Train net output #0: loss = 1.63879 (* 1 = 1.63879 loss)
I0713 18:28:19.486985  6493 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0713 18:29:07.071195  6493 solver.cpp:235] Iteration 550, loss = 1.21748
I0713 18:29:07.071593  6493 solver.cpp:255]     Train net output #0: loss = 1.21748 (* 1 = 1.21748 loss)
I0713 18:29:07.071702  6493 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0713 18:29:54.633301  6493 solver.cpp:235] Iteration 560, loss = 0.963371
I0713 18:29:54.633705  6493 solver.cpp:255]     Train net output #0: loss = 0.963371 (* 1 = 0.963371 loss)
I0713 18:29:54.633824  6493 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0713 18:30:42.227902  6493 solver.cpp:235] Iteration 570, loss = 0.896914
I0713 18:30:42.228307  6493 solver.cpp:255]     Train net output #0: loss = 0.896914 (* 1 = 0.896914 loss)
I0713 18:30:42.228549  6493 sgd_solver.cpp:106] Iteration 570, lr = 0.001
I0713 18:31:29.787822  6493 solver.cpp:235] Iteration 580, loss = 0.933182
I0713 18:31:29.788179  6493 solver.cpp:255]     Train net output #0: loss = 0.933182 (* 1 = 0.933182 loss)
I0713 18:31:29.788403  6493 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0713 18:32:17.359848  6493 solver.cpp:235] Iteration 590, loss = 0.572758
I0713 18:32:17.360374  6493 solver.cpp:255]     Train net output #0: loss = 0.572758 (* 1 = 0.572758 loss)
I0713 18:32:17.360504  6493 sgd_solver.cpp:106] Iteration 590, lr = 0.001
I0713 18:33:00.278357  6493 solver.cpp:352] Iteration 600, Testing net (#0)
I0713 18:36:14.000809  6493 solver.cpp:419]     Test net output #0: loss = 0.84282 (* 1 = 0.84282 loss)
I0713 18:36:15.353579  6493 solver.cpp:235] Iteration 600, loss = 0.677882
I0713 18:36:15.353790  6493 solver.cpp:255]     Train net output #0: loss = 0.677882 (* 1 = 0.677882 loss)
I0713 18:36:15.354040  6493 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0713 18:37:02.893517  6493 solver.cpp:235] Iteration 610, loss = 1.13438
I0713 18:37:02.893976  6493 solver.cpp:255]     Train net output #0: loss = 1.13438 (* 1 = 1.13438 loss)
I0713 18:37:02.894223  6493 sgd_solver.cpp:106] Iteration 610, lr = 0.001
I0713 18:37:50.434629  6493 solver.cpp:235] Iteration 620, loss = 1.13233
I0713 18:37:50.435046  6493 solver.cpp:255]     Train net output #0: loss = 1.13233 (* 1 = 1.13233 loss)
I0713 18:37:50.435165  6493 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0713 18:38:38.005240  6493 solver.cpp:235] Iteration 630, loss = 0.852186
I0713 18:38:38.005662  6493 solver.cpp:255]     Train net output #0: loss = 0.852186 (* 1 = 0.852186 loss)
I0713 18:38:38.005769  6493 sgd_solver.cpp:106] Iteration 630, lr = 0.001
I0713 18:39:25.600422  6493 solver.cpp:235] Iteration 640, loss = 0.826335
I0713 18:39:25.600798  6493 solver.cpp:255]     Train net output #0: loss = 0.826335 (* 1 = 0.826335 loss)
I0713 18:39:25.600908  6493 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0713 18:40:13.184381  6493 solver.cpp:235] Iteration 650, loss = 0.784813
I0713 18:40:13.184895  6493 solver.cpp:255]     Train net output #0: loss = 0.784813 (* 1 = 0.784813 loss)
I0713 18:40:13.185004  6493 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0713 18:41:00.749383  6493 solver.cpp:235] Iteration 660, loss = 1.03722
I0713 18:41:00.749778  6493 solver.cpp:255]     Train net output #0: loss = 1.03722 (* 1 = 1.03722 loss)
I0713 18:41:00.749886  6493 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0713 18:41:48.282093  6493 solver.cpp:235] Iteration 670, loss = 1.07363
I0713 18:41:48.282577  6493 solver.cpp:255]     Train net output #0: loss = 1.07363 (* 1 = 1.07363 loss)
I0713 18:41:48.282680  6493 sgd_solver.cpp:106] Iteration 670, lr = 0.001
I0713 18:42:35.866874  6493 solver.cpp:235] Iteration 680, loss = 0.998318
I0713 18:42:35.867287  6493 solver.cpp:255]     Train net output #0: loss = 0.998318 (* 1 = 0.998318 loss)
I0713 18:42:35.867404  6493 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0713 18:43:23.436110  6493 solver.cpp:235] Iteration 690, loss = 0.988036
I0713 18:43:23.436563  6493 solver.cpp:255]     Train net output #0: loss = 0.988036 (* 1 = 0.988036 loss)
I0713 18:43:23.436664  6493 sgd_solver.cpp:106] Iteration 690, lr = 0.001
I0713 18:44:11.037935  6493 solver.cpp:235] Iteration 700, loss = 0.770034
I0713 18:44:11.038427  6493 solver.cpp:255]     Train net output #0: loss = 0.770034 (* 1 = 0.770034 loss)
I0713 18:44:11.038532  6493 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0713 18:44:58.586442  6493 solver.cpp:235] Iteration 710, loss = 0.922384
I0713 18:44:58.586864  6493 solver.cpp:255]     Train net output #0: loss = 0.922384 (* 1 = 0.922384 loss)
I0713 18:44:58.587117  6493 sgd_solver.cpp:106] Iteration 710, lr = 0.001
I0713 18:45:46.159477  6493 solver.cpp:235] Iteration 720, loss = 1.0815
I0713 18:45:46.159941  6493 solver.cpp:255]     Train net output #0: loss = 1.0815 (* 1 = 1.0815 loss)
I0713 18:45:46.160068  6493 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0713 18:46:33.707972  6493 solver.cpp:235] Iteration 730, loss = 1.24274
I0713 18:46:33.708495  6493 solver.cpp:255]     Train net output #0: loss = 1.24274 (* 1 = 1.24274 loss)
I0713 18:46:33.708634  6493 sgd_solver.cpp:106] Iteration 730, lr = 0.001
I0713 18:47:21.282819  6493 solver.cpp:235] Iteration 740, loss = 1.01109
I0713 18:47:21.283237  6493 solver.cpp:255]     Train net output #0: loss = 1.01109 (* 1 = 1.01109 loss)
I0713 18:47:21.283341  6493 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0713 18:48:08.862401  6493 solver.cpp:235] Iteration 750, loss = 0.92064
I0713 18:48:08.862941  6493 solver.cpp:255]     Train net output #0: loss = 0.92064 (* 1 = 0.92064 loss)
I0713 18:48:08.863056  6493 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0713 18:48:56.451385  6493 solver.cpp:235] Iteration 760, loss = 0.778309
I0713 18:48:56.451863  6493 solver.cpp:255]     Train net output #0: loss = 0.778309 (* 1 = 0.778309 loss)
I0713 18:48:56.451966  6493 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0713 18:49:44.050153  6493 solver.cpp:235] Iteration 770, loss = 0.619426
I0713 18:49:44.053122  6493 solver.cpp:255]     Train net output #0: loss = 0.619426 (* 1 = 0.619426 loss)
I0713 18:49:44.053380  6493 sgd_solver.cpp:106] Iteration 770, lr = 0.001
I0713 18:50:31.591281  6493 solver.cpp:235] Iteration 780, loss = 1.12336
I0713 18:50:31.591775  6493 solver.cpp:255]     Train net output #0: loss = 1.12336 (* 1 = 1.12336 loss)
I0713 18:50:31.592061  6493 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0713 18:51:19.136752  6493 solver.cpp:235] Iteration 790, loss = 1.34255
I0713 18:51:19.137231  6493 solver.cpp:255]     Train net output #0: loss = 1.34255 (* 1 = 1.34255 loss)
I0713 18:51:19.137337  6493 sgd_solver.cpp:106] Iteration 790, lr = 0.001
I0713 18:52:02.041079  6493 solver.cpp:352] Iteration 800, Testing net (#0)
I0713 18:55:15.879926  6493 solver.cpp:419]     Test net output #0: loss = 0.886286 (* 1 = 0.886286 loss)
I0713 18:55:17.227488  6493 solver.cpp:235] Iteration 800, loss = 0.768972
I0713 18:55:17.227699  6493 solver.cpp:255]     Train net output #0: loss = 0.768972 (* 1 = 0.768972 loss)
I0713 18:55:17.227819  6493 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0713 18:56:04.773741  6493 solver.cpp:235] Iteration 810, loss = 0.993636
I0713 18:56:04.774235  6493 solver.cpp:255]     Train net output #0: loss = 0.993636 (* 1 = 0.993636 loss)
I0713 18:56:04.774379  6493 sgd_solver.cpp:106] Iteration 810, lr = 0.001
I0713 18:56:52.307301  6493 solver.cpp:235] Iteration 820, loss = 0.825498
I0713 18:56:52.307811  6493 solver.cpp:255]     Train net output #0: loss = 0.825498 (* 1 = 0.825498 loss)
I0713 18:56:52.308115  6493 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0713 18:57:39.889544  6493 solver.cpp:235] Iteration 830, loss = 1.0371
I0713 18:57:39.889973  6493 solver.cpp:255]     Train net output #0: loss = 1.0371 (* 1 = 1.0371 loss)
I0713 18:57:39.890254  6493 sgd_solver.cpp:106] Iteration 830, lr = 0.001
I0713 18:58:27.437681  6493 solver.cpp:235] Iteration 840, loss = 0.750214
I0713 18:58:27.438056  6493 solver.cpp:255]     Train net output #0: loss = 0.750214 (* 1 = 0.750214 loss)
I0713 18:58:27.438158  6493 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0713 18:59:14.985909  6493 solver.cpp:235] Iteration 850, loss = 0.921222
I0713 18:59:14.986364  6493 solver.cpp:255]     Train net output #0: loss = 0.921222 (* 1 = 0.921222 loss)
I0713 18:59:14.986601  6493 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0713 19:00:02.530730  6493 solver.cpp:235] Iteration 860, loss = 1.04
I0713 19:00:02.531203  6493 solver.cpp:255]     Train net output #0: loss = 1.04 (* 1 = 1.04 loss)
I0713 19:00:02.531303  6493 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0713 19:00:50.089560  6493 solver.cpp:235] Iteration 870, loss = 0.900356
I0713 19:00:50.090672  6493 solver.cpp:255]     Train net output #0: loss = 0.900356 (* 1 = 0.900356 loss)
I0713 19:00:50.090775  6493 sgd_solver.cpp:106] Iteration 870, lr = 0.001
I0713 19:01:37.641219  6493 solver.cpp:235] Iteration 880, loss = 0.57559
I0713 19:01:37.641651  6493 solver.cpp:255]     Train net output #0: loss = 0.57559 (* 1 = 0.57559 loss)
I0713 19:01:37.641762  6493 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0713 19:02:25.191650  6493 solver.cpp:235] Iteration 890, loss = 1.00907
I0713 19:02:25.192112  6493 solver.cpp:255]     Train net output #0: loss = 1.00907 (* 1 = 1.00907 loss)
I0713 19:02:25.192214  6493 sgd_solver.cpp:106] Iteration 890, lr = 0.001
I0713 19:03:12.735388  6493 solver.cpp:235] Iteration 900, loss = 0.485695
I0713 19:03:12.735875  6493 solver.cpp:255]     Train net output #0: loss = 0.485695 (* 1 = 0.485695 loss)
I0713 19:03:12.735983  6493 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0713 19:04:00.284229  6493 solver.cpp:235] Iteration 910, loss = 1.36594
I0713 19:04:00.284624  6493 solver.cpp:255]     Train net output #0: loss = 1.36594 (* 1 = 1.36594 loss)
I0713 19:04:00.284759  6493 sgd_solver.cpp:106] Iteration 910, lr = 0.001
I0713 19:04:47.864239  6493 solver.cpp:235] Iteration 920, loss = 0.798034
I0713 19:04:47.864593  6493 solver.cpp:255]     Train net output #0: loss = 0.798034 (* 1 = 0.798034 loss)
I0713 19:04:47.864698  6493 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0713 19:05:35.397444  6493 solver.cpp:235] Iteration 930, loss = 0.765363
I0713 19:05:35.397923  6493 solver.cpp:255]     Train net output #0: loss = 0.765363 (* 1 = 0.765363 loss)
I0713 19:05:35.398195  6493 sgd_solver.cpp:106] Iteration 930, lr = 0.001
I0713 19:06:22.960688  6493 solver.cpp:235] Iteration 940, loss = 0.789425
I0713 19:06:22.961132  6493 solver.cpp:255]     Train net output #0: loss = 0.789425 (* 1 = 0.789425 loss)
I0713 19:06:22.961262  6493 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0713 19:07:10.467615  6493 solver.cpp:235] Iteration 950, loss = 0.559972
I0713 19:07:10.468065  6493 solver.cpp:255]     Train net output #0: loss = 0.559972 (* 1 = 0.559972 loss)
I0713 19:07:10.468171  6493 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0713 19:07:57.995187  6493 solver.cpp:235] Iteration 960, loss = 1.16394
I0713 19:07:57.995592  6493 solver.cpp:255]     Train net output #0: loss = 1.16394 (* 1 = 1.16394 loss)
I0713 19:07:57.995707  6493 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0713 19:08:45.559955  6493 solver.cpp:235] Iteration 970, loss = 0.749686
I0713 19:08:45.560398  6493 solver.cpp:255]     Train net output #0: loss = 0.749686 (* 1 = 0.749686 loss)
I0713 19:08:45.560506  6493 sgd_solver.cpp:106] Iteration 970, lr = 0.001
I0713 19:09:33.116955  6493 solver.cpp:235] Iteration 980, loss = 0.641566
I0713 19:09:33.117436  6493 solver.cpp:255]     Train net output #0: loss = 0.641566 (* 1 = 0.641566 loss)
I0713 19:09:33.117720  6493 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0713 19:10:20.689105  6493 solver.cpp:235] Iteration 990, loss = 1.22275
I0713 19:10:20.689604  6493 solver.cpp:255]     Train net output #0: loss = 1.22275 (* 1 = 1.22275 loss)
I0713 19:10:20.689885  6493 sgd_solver.cpp:106] Iteration 990, lr = 0.001
I0713 19:11:03.530834  6493 solver.cpp:352] Iteration 1000, Testing net (#0)
I0713 19:14:17.225680  6493 solver.cpp:419]     Test net output #0: loss = 0.867116 (* 1 = 0.867116 loss)
I0713 19:14:18.576333  6493 solver.cpp:235] Iteration 1000, loss = 1.08052
I0713 19:14:18.576563  6493 solver.cpp:255]     Train net output #0: loss = 1.08052 (* 1 = 1.08052 loss)
I0713 19:14:18.576828  6493 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0713 19:15:06.176833  6493 solver.cpp:235] Iteration 1010, loss = 0.663189
I0713 19:15:06.177255  6493 solver.cpp:255]     Train net output #0: loss = 0.663189 (* 1 = 0.663189 loss)
I0713 19:15:06.177496  6493 sgd_solver.cpp:106] Iteration 1010, lr = 0.001
I0713 19:15:53.746395  6493 solver.cpp:235] Iteration 1020, loss = 0.7263
I0713 19:15:53.746867  6493 solver.cpp:255]     Train net output #0: loss = 0.7263 (* 1 = 0.7263 loss)
I0713 19:15:53.747120  6493 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0713 19:16:41.326169  6493 solver.cpp:235] Iteration 1030, loss = 1.1545
I0713 19:16:41.326580  6493 solver.cpp:255]     Train net output #0: loss = 1.1545 (* 1 = 1.1545 loss)
I0713 19:16:41.326695  6493 sgd_solver.cpp:106] Iteration 1030, lr = 0.001
I0713 19:17:28.907084  6493 solver.cpp:235] Iteration 1040, loss = 0.755024
I0713 19:17:28.907500  6493 solver.cpp:255]     Train net output #0: loss = 0.755024 (* 1 = 0.755024 loss)
I0713 19:17:28.907605  6493 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0713 19:18:16.450002  6493 solver.cpp:235] Iteration 1050, loss = 1.59739
I0713 19:18:16.450489  6493 solver.cpp:255]     Train net output #0: loss = 1.59739 (* 1 = 1.59739 loss)
I0713 19:18:16.450613  6493 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0713 19:19:04.049263  6493 solver.cpp:235] Iteration 1060, loss = 0.693475
I0713 19:19:04.049782  6493 solver.cpp:255]     Train net output #0: loss = 0.693475 (* 1 = 0.693475 loss)
I0713 19:19:04.049891  6493 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0713 19:19:51.609179  6493 solver.cpp:235] Iteration 1070, loss = 0.534989
I0713 19:19:51.609540  6493 solver.cpp:255]     Train net output #0: loss = 0.534989 (* 1 = 0.534989 loss)
I0713 19:19:51.609644  6493 sgd_solver.cpp:106] Iteration 1070, lr = 0.001
I0713 19:20:39.183894  6493 solver.cpp:235] Iteration 1080, loss = 1.07717
I0713 19:20:39.184315  6493 solver.cpp:255]     Train net output #0: loss = 1.07717 (* 1 = 1.07717 loss)
I0713 19:20:39.184418  6493 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0713 19:21:26.729578  6493 solver.cpp:235] Iteration 1090, loss = 0.812186
I0713 19:21:26.730002  6493 solver.cpp:255]     Train net output #0: loss = 0.812186 (* 1 = 0.812186 loss)
I0713 19:21:26.730240  6493 sgd_solver.cpp:106] Iteration 1090, lr = 0.001
I0713 19:22:14.318822  6493 solver.cpp:235] Iteration 1100, loss = 0.667985
I0713 19:22:14.319236  6493 solver.cpp:255]     Train net output #0: loss = 0.667985 (* 1 = 0.667985 loss)
I0713 19:22:14.319499  6493 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0713 19:23:01.858717  6493 solver.cpp:235] Iteration 1110, loss = 0.611767
I0713 19:23:01.859199  6493 solver.cpp:255]     Train net output #0: loss = 0.611767 (* 1 = 0.611767 loss)
I0713 19:23:01.859302  6493 sgd_solver.cpp:106] Iteration 1110, lr = 0.001
I0713 19:23:49.461894  6493 solver.cpp:235] Iteration 1120, loss = 0.6308
I0713 19:23:49.462440  6493 solver.cpp:255]     Train net output #0: loss = 0.6308 (* 1 = 0.6308 loss)
I0713 19:23:49.462546  6493 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0713 19:24:37.076897  6493 solver.cpp:235] Iteration 1130, loss = 0.514771
I0713 19:24:37.077406  6493 solver.cpp:255]     Train net output #0: loss = 0.514771 (* 1 = 0.514771 loss)
I0713 19:24:37.077687  6493 sgd_solver.cpp:106] Iteration 1130, lr = 0.001
I0713 19:25:24.704140  6493 solver.cpp:235] Iteration 1140, loss = 0.673608
I0713 19:25:24.704620  6493 solver.cpp:255]     Train net output #0: loss = 0.673608 (* 1 = 0.673608 loss)
I0713 19:25:24.704746  6493 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0713 19:26:12.237574  6493 solver.cpp:235] Iteration 1150, loss = 0.791207
I0713 19:26:12.238015  6493 solver.cpp:255]     Train net output #0: loss = 0.791207 (* 1 = 0.791207 loss)
I0713 19:26:12.238122  6493 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0713 19:26:59.778556  6493 solver.cpp:235] Iteration 1160, loss = 0.82686
I0713 19:26:59.779027  6493 solver.cpp:255]     Train net output #0: loss = 0.82686 (* 1 = 0.82686 loss)
I0713 19:26:59.779271  6493 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0713 19:27:47.352452  6493 solver.cpp:235] Iteration 1170, loss = 0.939884
I0713 19:27:47.352874  6493 solver.cpp:255]     Train net output #0: loss = 0.939884 (* 1 = 0.939884 loss)
I0713 19:27:47.352985  6493 sgd_solver.cpp:106] Iteration 1170, lr = 0.001
I0713 19:28:34.897145  6493 solver.cpp:235] Iteration 1180, loss = 1.02018
I0713 19:28:34.897586  6493 solver.cpp:255]     Train net output #0: loss = 1.02018 (* 1 = 1.02018 loss)
I0713 19:28:34.897691  6493 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0713 19:29:22.457350  6493 solver.cpp:235] Iteration 1190, loss = 0.751732
I0713 19:29:22.457783  6493 solver.cpp:255]     Train net output #0: loss = 0.751732 (* 1 = 0.751732 loss)
I0713 19:29:22.457885  6493 sgd_solver.cpp:106] Iteration 1190, lr = 0.001
I0713 19:30:05.278316  6493 solver.cpp:352] Iteration 1200, Testing net (#0)
I0713 19:33:18.894157  6493 solver.cpp:419]     Test net output #0: loss = 0.755312 (* 1 = 0.755312 loss)
I0713 19:33:20.244210  6493 solver.cpp:235] Iteration 1200, loss = 0.589302
I0713 19:33:20.244443  6493 solver.cpp:255]     Train net output #0: loss = 0.589302 (* 1 = 0.589302 loss)
I0713 19:33:20.244549  6493 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0713 19:34:07.801426  6493 solver.cpp:235] Iteration 1210, loss = 0.482413
I0713 19:34:07.801913  6493 solver.cpp:255]     Train net output #0: loss = 0.482413 (* 1 = 0.482413 loss)
I0713 19:34:07.802176  6493 sgd_solver.cpp:106] Iteration 1210, lr = 0.001
I0713 19:34:55.273936  6493 solver.cpp:235] Iteration 1220, loss = 0.706228
I0713 19:34:55.274345  6493 solver.cpp:255]     Train net output #0: loss = 0.706228 (* 1 = 0.706228 loss)
I0713 19:34:55.274627  6493 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0713 19:35:42.793328  6493 solver.cpp:235] Iteration 1230, loss = 0.963985
I0713 19:35:42.793759  6493 solver.cpp:255]     Train net output #0: loss = 0.963985 (* 1 = 0.963985 loss)
I0713 19:35:42.794060  6493 sgd_solver.cpp:106] Iteration 1230, lr = 0.001
I0713 19:36:30.334677  6493 solver.cpp:235] Iteration 1240, loss = 0.701198
I0713 19:36:30.335150  6493 solver.cpp:255]     Train net output #0: loss = 0.701198 (* 1 = 0.701198 loss)
I0713 19:36:30.335422  6493 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0713 19:37:17.866703  6493 solver.cpp:235] Iteration 1250, loss = 0.587571
I0713 19:37:17.867123  6493 solver.cpp:255]     Train net output #0: loss = 0.587572 (* 1 = 0.587572 loss)
I0713 19:37:17.867249  6493 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0713 19:38:05.410375  6493 solver.cpp:235] Iteration 1260, loss = 0.867784
I0713 19:38:05.410820  6493 solver.cpp:255]     Train net output #0: loss = 0.867784 (* 1 = 0.867784 loss)
I0713 19:38:05.410928  6493 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0713 19:38:53.004326  6493 solver.cpp:235] Iteration 1270, loss = 0.561978
I0713 19:38:53.004829  6493 solver.cpp:255]     Train net output #0: loss = 0.561978 (* 1 = 0.561978 loss)
I0713 19:38:53.004938  6493 sgd_solver.cpp:106] Iteration 1270, lr = 0.001
I0713 19:39:40.573218  6493 solver.cpp:235] Iteration 1280, loss = 0.723698
I0713 19:39:40.573627  6493 solver.cpp:255]     Train net output #0: loss = 0.723698 (* 1 = 0.723698 loss)
I0713 19:39:40.573729  6493 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0713 19:40:28.132361  6493 solver.cpp:235] Iteration 1290, loss = 0.75681
I0713 19:40:28.132760  6493 solver.cpp:255]     Train net output #0: loss = 0.75681 (* 1 = 0.75681 loss)
I0713 19:40:28.132869  6493 sgd_solver.cpp:106] Iteration 1290, lr = 0.001
I0713 19:41:15.723346  6493 solver.cpp:235] Iteration 1300, loss = 1.06121
I0713 19:41:15.723803  6493 solver.cpp:255]     Train net output #0: loss = 1.06121 (* 1 = 1.06121 loss)
I0713 19:41:15.723908  6493 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0713 19:42:03.273494  6493 solver.cpp:235] Iteration 1310, loss = 0.587853
I0713 19:42:03.273965  6493 solver.cpp:255]     Train net output #0: loss = 0.587853 (* 1 = 0.587853 loss)
I0713 19:42:03.274070  6493 sgd_solver.cpp:106] Iteration 1310, lr = 0.001
I0713 19:42:50.818150  6493 solver.cpp:235] Iteration 1320, loss = 0.486351
I0713 19:42:50.818599  6493 solver.cpp:255]     Train net output #0: loss = 0.486351 (* 1 = 0.486351 loss)
I0713 19:42:50.818703  6493 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0713 19:43:38.360707  6493 solver.cpp:235] Iteration 1330, loss = 0.536404
I0713 19:43:38.361161  6493 solver.cpp:255]     Train net output #0: loss = 0.536404 (* 1 = 0.536404 loss)
I0713 19:43:38.361407  6493 sgd_solver.cpp:106] Iteration 1330, lr = 0.001
I0713 19:44:25.875529  6493 solver.cpp:235] Iteration 1340, loss = 1.14408
I0713 19:44:25.875994  6493 solver.cpp:255]     Train net output #0: loss = 1.14408 (* 1 = 1.14408 loss)
I0713 19:44:25.876123  6493 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0713 19:45:13.435245  6493 solver.cpp:235] Iteration 1350, loss = 0.503708
I0713 19:45:13.435621  6493 solver.cpp:255]     Train net output #0: loss = 0.503708 (* 1 = 0.503708 loss)
I0713 19:45:13.435853  6493 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0713 19:46:00.981330  6493 solver.cpp:235] Iteration 1360, loss = 0.57627
I0713 19:46:00.981787  6493 solver.cpp:255]     Train net output #0: loss = 0.57627 (* 1 = 0.57627 loss)
I0713 19:46:00.981889  6493 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0713 19:46:48.516233  6493 solver.cpp:235] Iteration 1370, loss = 0.52296
I0713 19:46:48.516685  6493 solver.cpp:255]     Train net output #0: loss = 0.52296 (* 1 = 0.52296 loss)
I0713 19:46:48.516799  6493 sgd_solver.cpp:106] Iteration 1370, lr = 0.001
I0713 19:47:36.073303  6493 solver.cpp:235] Iteration 1380, loss = 0.587413
I0713 19:47:36.073796  6493 solver.cpp:255]     Train net output #0: loss = 0.587413 (* 1 = 0.587413 loss)
I0713 19:47:36.074090  6493 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0713 19:48:23.617100  6493 solver.cpp:235] Iteration 1390, loss = 0.986562
I0713 19:48:23.617621  6493 solver.cpp:255]     Train net output #0: loss = 0.986562 (* 1 = 0.986562 loss)
I0713 19:48:23.617727  6493 sgd_solver.cpp:106] Iteration 1390, lr = 0.001
I0713 19:49:06.497246  6493 solver.cpp:352] Iteration 1400, Testing net (#0)
I0713 19:52:20.221673  6493 solver.cpp:419]     Test net output #0: loss = 0.713077 (* 1 = 0.713077 loss)
I0713 19:52:21.571712  6493 solver.cpp:235] Iteration 1400, loss = 0.505976
I0713 19:52:21.571931  6493 solver.cpp:255]     Train net output #0: loss = 0.505976 (* 1 = 0.505976 loss)
I0713 19:52:21.572191  6493 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0713 19:53:09.080936  6493 solver.cpp:235] Iteration 1410, loss = 0.646247
I0713 19:53:09.081390  6493 solver.cpp:255]     Train net output #0: loss = 0.646247 (* 1 = 0.646247 loss)
I0713 19:53:09.081634  6493 sgd_solver.cpp:106] Iteration 1410, lr = 0.001
