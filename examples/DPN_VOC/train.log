I0713 17:35:53.970674  6493 caffe.cpp:217] Using GPUs 0
I0713 17:35:54.000095  6493 caffe.cpp:222] GPU 0: GeForce GTX TITAN X
I0713 17:35:54.288296  6493 solver.cpp:50] Initializing solver from parameters: 
test_iter: 720
test_interval: 200
base_lr: 0.001
display: 10
max_iter: 9000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 6000
snapshot: 2000
snapshot_prefix: "examples/DPN_VOC/model/unary"
solver_mode: GPU
device_id: 0
net: "examples/DPN_VOC/DPN_VOC.prototxt"
train_state {
  level: 0
  stage: ""
}
pavi_log: true
pavi_server_host: "pavi.parrotsdnn.org"
pavi_username: "xxli"
pavi_password: "123456"
session: "DPN_VOC_unary"
workdir: "examples/DPN_VOC/"
I0713 17:35:54.288553  6493 solver.cpp:98] Creating training net from net file: examples/DPN_VOC/DPN_VOC.prototxt
I0713 17:35:54.289996  6493 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0713 17:35:54.290410  6493 net.cpp:58] Initializing net from parameters: 
name: "DPN"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 480
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
    crop_resize: 0.8
    crop_resize: 1
    label_crop_size: 96
  }
  image_data_param {
    source: "data/VOC_arg/train.txt"
    batch_size: 10
    shuffle: true
    root_folder: "data/VOC_arg"
    label_type: PIXEL
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-VOC"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-VOC"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "fc8-VOC"
  top: "upscore"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 21
    bias_term: false
    pad: 4
    kernel_size: 16
    group: 21
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upscore"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
    hm_ratio: 0.5
  }
}
I0713 17:35:54.290702  6493 layer_factory.hpp:77] Creating layer data
I0713 17:35:54.290776  6493 net.cpp:100] Creating Layer data
I0713 17:35:54.290794  6493 net.cpp:408] data -> data
I0713 17:35:54.290848  6493 net.cpp:408] data -> label
I0713 17:35:54.291313  6493 image_seg_data_layer.cpp:45] Opening file data/VOC_arg/train.txt
I0713 17:35:54.311583  6493 image_seg_data_layer.cpp:101] Shuffling data
I0713 17:35:54.311841  6493 image_seg_data_layer.cpp:106] A total of 10582 images.
I0713 17:35:54.351557  6493 image_seg_data_layer.cpp:179] output data size: 10,3,480,480
I0713 17:35:54.351598  6493 image_seg_data_layer.cpp:183] output label size: 10,1,288,288
I0713 17:35:54.429214  6493 net.cpp:150] Setting up data
I0713 17:35:54.429322  6493 net.cpp:157] Top shape: 10 3 480 480 (6912000)
I0713 17:35:54.429335  6493 net.cpp:157] Top shape: 10 1 288 288 (829440)
I0713 17:35:54.429343  6493 net.cpp:165] Memory required for data: 30965760
I0713 17:35:54.429360  6493 layer_factory.hpp:77] Creating layer conv1_1
I0713 17:35:54.429404  6493 net.cpp:100] Creating Layer conv1_1
I0713 17:35:54.429419  6493 net.cpp:434] conv1_1 <- data
I0713 17:35:54.429443  6493 net.cpp:408] conv1_1 -> conv1_1
I0713 17:35:54.431579  6493 net.cpp:150] Setting up conv1_1
I0713 17:35:54.431602  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.431609  6493 net.cpp:165] Memory required for data: 620789760
I0713 17:35:54.431635  6493 layer_factory.hpp:77] Creating layer relu1_1
I0713 17:35:54.431653  6493 net.cpp:100] Creating Layer relu1_1
I0713 17:35:54.431663  6493 net.cpp:434] relu1_1 <- conv1_1
I0713 17:35:54.431674  6493 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0713 17:35:54.431691  6493 net.cpp:150] Setting up relu1_1
I0713 17:35:54.431702  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.431710  6493 net.cpp:165] Memory required for data: 1210613760
I0713 17:35:54.431716  6493 layer_factory.hpp:77] Creating layer conv1_2
I0713 17:35:54.431730  6493 net.cpp:100] Creating Layer conv1_2
I0713 17:35:54.431738  6493 net.cpp:434] conv1_2 <- conv1_1
I0713 17:35:54.431751  6493 net.cpp:408] conv1_2 -> conv1_2
I0713 17:35:54.433773  6493 net.cpp:150] Setting up conv1_2
I0713 17:35:54.433797  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.433805  6493 net.cpp:165] Memory required for data: 1800437760
I0713 17:35:54.433821  6493 layer_factory.hpp:77] Creating layer relu1_2
I0713 17:35:54.433835  6493 net.cpp:100] Creating Layer relu1_2
I0713 17:35:54.433845  6493 net.cpp:434] relu1_2 <- conv1_2
I0713 17:35:54.433856  6493 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0713 17:35:54.433867  6493 net.cpp:150] Setting up relu1_2
I0713 17:35:54.433876  6493 net.cpp:157] Top shape: 10 64 480 480 (147456000)
I0713 17:35:54.433883  6493 net.cpp:165] Memory required for data: 2390261760
I0713 17:35:54.433890  6493 layer_factory.hpp:77] Creating layer pool1
I0713 17:35:54.433902  6493 net.cpp:100] Creating Layer pool1
I0713 17:35:54.433909  6493 net.cpp:434] pool1 <- conv1_2
I0713 17:35:54.433920  6493 net.cpp:408] pool1 -> pool1
I0713 17:35:54.438539  6493 net.cpp:150] Setting up pool1
I0713 17:35:54.438567  6493 net.cpp:157] Top shape: 10 64 240 240 (36864000)
I0713 17:35:54.438575  6493 net.cpp:165] Memory required for data: 2537717760
I0713 17:35:54.438582  6493 layer_factory.hpp:77] Creating layer conv2_1
I0713 17:35:54.438599  6493 net.cpp:100] Creating Layer conv2_1
I0713 17:35:54.438607  6493 net.cpp:434] conv2_1 <- pool1
I0713 17:35:54.438619  6493 net.cpp:408] conv2_1 -> conv2_1
I0713 17:35:54.439668  6493 net.cpp:150] Setting up conv2_1
I0713 17:35:54.439689  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.439697  6493 net.cpp:165] Memory required for data: 2832629760
I0713 17:35:54.439756  6493 layer_factory.hpp:77] Creating layer relu2_1
I0713 17:35:54.439770  6493 net.cpp:100] Creating Layer relu2_1
I0713 17:35:54.439779  6493 net.cpp:434] relu2_1 <- conv2_1
I0713 17:35:54.439788  6493 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0713 17:35:54.439801  6493 net.cpp:150] Setting up relu2_1
I0713 17:35:54.439813  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.439820  6493 net.cpp:165] Memory required for data: 3127541760
I0713 17:35:54.439826  6493 layer_factory.hpp:77] Creating layer conv2_2
I0713 17:35:54.439842  6493 net.cpp:100] Creating Layer conv2_2
I0713 17:35:54.439851  6493 net.cpp:434] conv2_2 <- conv2_1
I0713 17:35:54.439862  6493 net.cpp:408] conv2_2 -> conv2_2
I0713 17:35:54.440248  6493 net.cpp:150] Setting up conv2_2
I0713 17:35:54.440264  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.440271  6493 net.cpp:165] Memory required for data: 3422453760
I0713 17:35:54.440284  6493 layer_factory.hpp:77] Creating layer relu2_2
I0713 17:35:54.440294  6493 net.cpp:100] Creating Layer relu2_2
I0713 17:35:54.440301  6493 net.cpp:434] relu2_2 <- conv2_2
I0713 17:35:54.440311  6493 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0713 17:35:54.440322  6493 net.cpp:150] Setting up relu2_2
I0713 17:35:54.440331  6493 net.cpp:157] Top shape: 10 128 240 240 (73728000)
I0713 17:35:54.440337  6493 net.cpp:165] Memory required for data: 3717365760
I0713 17:35:54.440346  6493 layer_factory.hpp:77] Creating layer pool2
I0713 17:35:54.440354  6493 net.cpp:100] Creating Layer pool2
I0713 17:35:54.440361  6493 net.cpp:434] pool2 <- conv2_2
I0713 17:35:54.440371  6493 net.cpp:408] pool2 -> pool2
I0713 17:35:54.440420  6493 net.cpp:150] Setting up pool2
I0713 17:35:54.440433  6493 net.cpp:157] Top shape: 10 128 120 120 (18432000)
I0713 17:35:54.440440  6493 net.cpp:165] Memory required for data: 3791093760
I0713 17:35:54.440446  6493 layer_factory.hpp:77] Creating layer conv3_1
I0713 17:35:54.440460  6493 net.cpp:100] Creating Layer conv3_1
I0713 17:35:54.440467  6493 net.cpp:434] conv3_1 <- pool2
I0713 17:35:54.440479  6493 net.cpp:408] conv3_1 -> conv3_1
I0713 17:35:54.442416  6493 net.cpp:150] Setting up conv3_1
I0713 17:35:54.442443  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.442451  6493 net.cpp:165] Memory required for data: 3938549760
I0713 17:35:54.442469  6493 layer_factory.hpp:77] Creating layer relu3_1
I0713 17:35:54.442482  6493 net.cpp:100] Creating Layer relu3_1
I0713 17:35:54.442489  6493 net.cpp:434] relu3_1 <- conv3_1
I0713 17:35:54.442500  6493 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0713 17:35:54.442513  6493 net.cpp:150] Setting up relu3_1
I0713 17:35:54.442523  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.442530  6493 net.cpp:165] Memory required for data: 4086005760
I0713 17:35:54.442538  6493 layer_factory.hpp:77] Creating layer conv3_2
I0713 17:35:54.442553  6493 net.cpp:100] Creating Layer conv3_2
I0713 17:35:54.442560  6493 net.cpp:434] conv3_2 <- conv3_1
I0713 17:35:54.442571  6493 net.cpp:408] conv3_2 -> conv3_2
I0713 17:35:54.444605  6493 net.cpp:150] Setting up conv3_2
I0713 17:35:54.444628  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.444636  6493 net.cpp:165] Memory required for data: 4233461760
I0713 17:35:54.444648  6493 layer_factory.hpp:77] Creating layer relu3_2
I0713 17:35:54.444659  6493 net.cpp:100] Creating Layer relu3_2
I0713 17:35:54.444667  6493 net.cpp:434] relu3_2 <- conv3_2
I0713 17:35:54.444677  6493 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0713 17:35:54.444690  6493 net.cpp:150] Setting up relu3_2
I0713 17:35:54.444700  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.444705  6493 net.cpp:165] Memory required for data: 4380917760
I0713 17:35:54.444722  6493 layer_factory.hpp:77] Creating layer conv3_3
I0713 17:35:54.444736  6493 net.cpp:100] Creating Layer conv3_3
I0713 17:35:54.444743  6493 net.cpp:434] conv3_3 <- conv3_2
I0713 17:35:54.444754  6493 net.cpp:408] conv3_3 -> conv3_3
I0713 17:35:54.446813  6493 net.cpp:150] Setting up conv3_3
I0713 17:35:54.446835  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.446843  6493 net.cpp:165] Memory required for data: 4528373760
I0713 17:35:54.446856  6493 layer_factory.hpp:77] Creating layer relu3_3
I0713 17:35:54.446871  6493 net.cpp:100] Creating Layer relu3_3
I0713 17:35:54.446878  6493 net.cpp:434] relu3_3 <- conv3_3
I0713 17:35:54.446888  6493 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0713 17:35:54.446902  6493 net.cpp:150] Setting up relu3_3
I0713 17:35:54.446910  6493 net.cpp:157] Top shape: 10 256 120 120 (36864000)
I0713 17:35:54.446918  6493 net.cpp:165] Memory required for data: 4675829760
I0713 17:35:54.446923  6493 layer_factory.hpp:77] Creating layer pool3
I0713 17:35:54.446934  6493 net.cpp:100] Creating Layer pool3
I0713 17:35:54.446943  6493 net.cpp:434] pool3 <- conv3_3
I0713 17:35:54.446951  6493 net.cpp:408] pool3 -> pool3
I0713 17:35:54.447003  6493 net.cpp:150] Setting up pool3
I0713 17:35:54.447017  6493 net.cpp:157] Top shape: 10 256 60 60 (9216000)
I0713 17:35:54.447023  6493 net.cpp:165] Memory required for data: 4712693760
I0713 17:35:54.447031  6493 layer_factory.hpp:77] Creating layer conv4_1
I0713 17:35:54.447044  6493 net.cpp:100] Creating Layer conv4_1
I0713 17:35:54.447052  6493 net.cpp:434] conv4_1 <- pool3
I0713 17:35:54.447062  6493 net.cpp:408] conv4_1 -> conv4_1
I0713 17:35:54.451524  6493 net.cpp:150] Setting up conv4_1
I0713 17:35:54.451565  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.451572  6493 net.cpp:165] Memory required for data: 4786421760
I0713 17:35:54.451586  6493 layer_factory.hpp:77] Creating layer relu4_1
I0713 17:35:54.451602  6493 net.cpp:100] Creating Layer relu4_1
I0713 17:35:54.451611  6493 net.cpp:434] relu4_1 <- conv4_1
I0713 17:35:54.451622  6493 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0713 17:35:54.451637  6493 net.cpp:150] Setting up relu4_1
I0713 17:35:54.451647  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.451653  6493 net.cpp:165] Memory required for data: 4860149760
I0713 17:35:54.451659  6493 layer_factory.hpp:77] Creating layer conv4_2
I0713 17:35:54.451675  6493 net.cpp:100] Creating Layer conv4_2
I0713 17:35:54.451686  6493 net.cpp:434] conv4_2 <- conv4_1
I0713 17:35:54.451697  6493 net.cpp:408] conv4_2 -> conv4_2
I0713 17:35:54.459305  6493 net.cpp:150] Setting up conv4_2
I0713 17:35:54.459372  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.459379  6493 net.cpp:165] Memory required for data: 4933877760
I0713 17:35:54.459409  6493 layer_factory.hpp:77] Creating layer relu4_2
I0713 17:35:54.459429  6493 net.cpp:100] Creating Layer relu4_2
I0713 17:35:54.459439  6493 net.cpp:434] relu4_2 <- conv4_2
I0713 17:35:54.459455  6493 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0713 17:35:54.459472  6493 net.cpp:150] Setting up relu4_2
I0713 17:35:54.459484  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.459491  6493 net.cpp:165] Memory required for data: 5007605760
I0713 17:35:54.459497  6493 layer_factory.hpp:77] Creating layer conv4_3
I0713 17:35:54.459513  6493 net.cpp:100] Creating Layer conv4_3
I0713 17:35:54.459522  6493 net.cpp:434] conv4_3 <- conv4_2
I0713 17:35:54.459532  6493 net.cpp:408] conv4_3 -> conv4_3
I0713 17:35:54.467427  6493 net.cpp:150] Setting up conv4_3
I0713 17:35:54.467491  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467499  6493 net.cpp:165] Memory required for data: 5081333760
I0713 17:35:54.467515  6493 layer_factory.hpp:77] Creating layer relu4_3
I0713 17:35:54.467535  6493 net.cpp:100] Creating Layer relu4_3
I0713 17:35:54.467543  6493 net.cpp:434] relu4_3 <- conv4_3
I0713 17:35:54.467558  6493 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0713 17:35:54.467576  6493 net.cpp:150] Setting up relu4_3
I0713 17:35:54.467586  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467592  6493 net.cpp:165] Memory required for data: 5155061760
I0713 17:35:54.467598  6493 layer_factory.hpp:77] Creating layer pool4
I0713 17:35:54.467656  6493 net.cpp:100] Creating Layer pool4
I0713 17:35:54.467664  6493 net.cpp:434] pool4 <- conv4_3
I0713 17:35:54.467676  6493 net.cpp:408] pool4 -> pool4
I0713 17:35:54.467733  6493 net.cpp:150] Setting up pool4
I0713 17:35:54.467747  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.467754  6493 net.cpp:165] Memory required for data: 5228789760
I0713 17:35:54.467761  6493 layer_factory.hpp:77] Creating layer conv5_1
I0713 17:35:54.467779  6493 net.cpp:100] Creating Layer conv5_1
I0713 17:35:54.467787  6493 net.cpp:434] conv5_1 <- pool4
I0713 17:35:54.467798  6493 net.cpp:408] conv5_1 -> conv5_1
I0713 17:35:54.475962  6493 net.cpp:150] Setting up conv5_1
I0713 17:35:54.476011  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.476019  6493 net.cpp:165] Memory required for data: 5302517760
I0713 17:35:54.476035  6493 layer_factory.hpp:77] Creating layer relu5_1
I0713 17:35:54.476054  6493 net.cpp:100] Creating Layer relu5_1
I0713 17:35:54.476064  6493 net.cpp:434] relu5_1 <- conv5_1
I0713 17:35:54.476079  6493 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0713 17:35:54.476099  6493 net.cpp:150] Setting up relu5_1
I0713 17:35:54.476107  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.476114  6493 net.cpp:165] Memory required for data: 5376245760
I0713 17:35:54.476120  6493 layer_factory.hpp:77] Creating layer conv5_2
I0713 17:35:54.476136  6493 net.cpp:100] Creating Layer conv5_2
I0713 17:35:54.476148  6493 net.cpp:434] conv5_2 <- conv5_1
I0713 17:35:54.476160  6493 net.cpp:408] conv5_2 -> conv5_2
I0713 17:35:54.484046  6493 net.cpp:150] Setting up conv5_2
I0713 17:35:54.484112  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.484122  6493 net.cpp:165] Memory required for data: 5449973760
I0713 17:35:54.484138  6493 layer_factory.hpp:77] Creating layer relu5_2
I0713 17:35:54.484158  6493 net.cpp:100] Creating Layer relu5_2
I0713 17:35:54.484176  6493 net.cpp:434] relu5_2 <- conv5_2
I0713 17:35:54.484191  6493 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0713 17:35:54.484210  6493 net.cpp:150] Setting up relu5_2
I0713 17:35:54.484220  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.484226  6493 net.cpp:165] Memory required for data: 5523701760
I0713 17:35:54.484233  6493 layer_factory.hpp:77] Creating layer conv5_3
I0713 17:35:54.484248  6493 net.cpp:100] Creating Layer conv5_3
I0713 17:35:54.484261  6493 net.cpp:434] conv5_3 <- conv5_2
I0713 17:35:54.484272  6493 net.cpp:408] conv5_3 -> conv5_3
I0713 17:35:54.492221  6493 net.cpp:150] Setting up conv5_3
I0713 17:35:54.492281  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492290  6493 net.cpp:165] Memory required for data: 5597429760
I0713 17:35:54.492307  6493 layer_factory.hpp:77] Creating layer relu5_3
I0713 17:35:54.492326  6493 net.cpp:100] Creating Layer relu5_3
I0713 17:35:54.492336  6493 net.cpp:434] relu5_3 <- conv5_3
I0713 17:35:54.492350  6493 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0713 17:35:54.492368  6493 net.cpp:150] Setting up relu5_3
I0713 17:35:54.492377  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492383  6493 net.cpp:165] Memory required for data: 5671157760
I0713 17:35:54.492390  6493 layer_factory.hpp:77] Creating layer pool5
I0713 17:35:54.492403  6493 net.cpp:100] Creating Layer pool5
I0713 17:35:54.492409  6493 net.cpp:434] pool5 <- conv5_3
I0713 17:35:54.492419  6493 net.cpp:408] pool5 -> pool5
I0713 17:35:54.492477  6493 net.cpp:150] Setting up pool5
I0713 17:35:54.492491  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492497  6493 net.cpp:165] Memory required for data: 5744885760
I0713 17:35:54.492506  6493 layer_factory.hpp:77] Creating layer pool5a
I0713 17:35:54.492522  6493 net.cpp:100] Creating Layer pool5a
I0713 17:35:54.492530  6493 net.cpp:434] pool5a <- pool5
I0713 17:35:54.492540  6493 net.cpp:408] pool5a -> pool5a
I0713 17:35:54.492573  6493 net.cpp:150] Setting up pool5a
I0713 17:35:54.492583  6493 net.cpp:157] Top shape: 10 512 60 60 (18432000)
I0713 17:35:54.492635  6493 net.cpp:165] Memory required for data: 5818613760
I0713 17:35:54.492643  6493 layer_factory.hpp:77] Creating layer fc6-conv
I0713 17:35:54.492660  6493 net.cpp:100] Creating Layer fc6-conv
I0713 17:35:54.492667  6493 net.cpp:434] fc6-conv <- pool5a
I0713 17:35:54.492678  6493 net.cpp:408] fc6-conv -> fc6-conv
I0713 17:35:54.804544  6493 net.cpp:150] Setting up fc6-conv
I0713 17:35:54.804616  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804625  6493 net.cpp:165] Memory required for data: 6030950400
I0713 17:35:54.804643  6493 layer_factory.hpp:77] Creating layer relu6
I0713 17:35:54.804663  6493 net.cpp:100] Creating Layer relu6
I0713 17:35:54.804682  6493 net.cpp:434] relu6 <- fc6-conv
I0713 17:35:54.804699  6493 net.cpp:395] relu6 -> fc6-conv (in-place)
I0713 17:35:54.804750  6493 net.cpp:150] Setting up relu6
I0713 17:35:54.804761  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804769  6493 net.cpp:165] Memory required for data: 6243287040
I0713 17:35:54.804775  6493 layer_factory.hpp:77] Creating layer drop6
I0713 17:35:54.804796  6493 net.cpp:100] Creating Layer drop6
I0713 17:35:54.804808  6493 net.cpp:434] drop6 <- fc6-conv
I0713 17:35:54.804817  6493 net.cpp:395] drop6 -> fc6-conv (in-place)
I0713 17:35:54.804869  6493 net.cpp:150] Setting up drop6
I0713 17:35:54.804883  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.804890  6493 net.cpp:165] Memory required for data: 6455623680
I0713 17:35:54.804898  6493 layer_factory.hpp:77] Creating layer fc7-conv
I0713 17:35:54.804913  6493 net.cpp:100] Creating Layer fc7-conv
I0713 17:35:54.804920  6493 net.cpp:434] fc7-conv <- fc6-conv
I0713 17:35:54.804931  6493 net.cpp:408] fc7-conv -> fc7-conv
I0713 17:35:54.855283  6493 net.cpp:150] Setting up fc7-conv
I0713 17:35:54.855345  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855353  6493 net.cpp:165] Memory required for data: 6667960320
I0713 17:35:54.855370  6493 layer_factory.hpp:77] Creating layer relu7
I0713 17:35:54.855389  6493 net.cpp:100] Creating Layer relu7
I0713 17:35:54.855398  6493 net.cpp:434] relu7 <- fc7-conv
I0713 17:35:54.855417  6493 net.cpp:395] relu7 -> fc7-conv (in-place)
I0713 17:35:54.855435  6493 net.cpp:150] Setting up relu7
I0713 17:35:54.855444  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855451  6493 net.cpp:165] Memory required for data: 6880296960
I0713 17:35:54.855458  6493 layer_factory.hpp:77] Creating layer drop7
I0713 17:35:54.855469  6493 net.cpp:100] Creating Layer drop7
I0713 17:35:54.855476  6493 net.cpp:434] drop7 <- fc7-conv
I0713 17:35:54.855485  6493 net.cpp:395] drop7 -> fc7-conv (in-place)
I0713 17:35:54.855523  6493 net.cpp:150] Setting up drop7
I0713 17:35:54.855536  6493 net.cpp:157] Top shape: 10 4096 36 36 (53084160)
I0713 17:35:54.855543  6493 net.cpp:165] Memory required for data: 7092633600
I0713 17:35:54.855551  6493 layer_factory.hpp:77] Creating layer fc8-VOC
I0713 17:35:54.855571  6493 net.cpp:100] Creating Layer fc8-VOC
I0713 17:35:54.855579  6493 net.cpp:434] fc8-VOC <- fc7-conv
I0713 17:35:54.855590  6493 net.cpp:408] fc8-VOC -> fc8-VOC
I0713 17:35:54.860226  6493 net.cpp:150] Setting up fc8-VOC
I0713 17:35:54.860249  6493 net.cpp:157] Top shape: 10 21 36 36 (272160)
I0713 17:35:54.860257  6493 net.cpp:165] Memory required for data: 7093722240
I0713 17:35:54.860268  6493 layer_factory.hpp:77] Creating layer upscore2
I0713 17:35:54.860288  6493 net.cpp:100] Creating Layer upscore2
I0713 17:35:54.860297  6493 net.cpp:434] upscore2 <- fc8-VOC
I0713 17:35:54.860311  6493 net.cpp:408] upscore2 -> upscore
I0713 17:35:54.860888  6493 net.cpp:150] Setting up upscore2
I0713 17:35:54.860904  6493 net.cpp:157] Top shape: 10 21 288 288 (17418240)
I0713 17:35:54.860910  6493 net.cpp:165] Memory required for data: 7163395200
I0713 17:35:54.860939  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:54.860955  6493 net.cpp:100] Creating Layer loss
I0713 17:35:54.860962  6493 net.cpp:434] loss <- upscore
I0713 17:35:54.861007  6493 net.cpp:434] loss <- label
I0713 17:35:54.861021  6493 net.cpp:408] loss -> loss
I0713 17:35:54.861057  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:54.919119  6493 net.cpp:150] Setting up loss
I0713 17:35:54.919176  6493 net.cpp:157] Top shape: (1)
I0713 17:35:54.919185  6493 net.cpp:160]     with loss weight 1
I0713 17:35:54.919226  6493 net.cpp:165] Memory required for data: 7163395204
I0713 17:35:54.919239  6493 net.cpp:226] loss needs backward computation.
I0713 17:35:54.919252  6493 net.cpp:226] upscore2 needs backward computation.
I0713 17:35:54.919260  6493 net.cpp:226] fc8-VOC needs backward computation.
I0713 17:35:54.919268  6493 net.cpp:226] drop7 needs backward computation.
I0713 17:35:54.919275  6493 net.cpp:226] relu7 needs backward computation.
I0713 17:35:54.919291  6493 net.cpp:226] fc7-conv needs backward computation.
I0713 17:35:54.919297  6493 net.cpp:226] drop6 needs backward computation.
I0713 17:35:54.919304  6493 net.cpp:226] relu6 needs backward computation.
I0713 17:35:54.919311  6493 net.cpp:226] fc6-conv needs backward computation.
I0713 17:35:54.919318  6493 net.cpp:226] pool5a needs backward computation.
I0713 17:35:54.919325  6493 net.cpp:226] pool5 needs backward computation.
I0713 17:35:54.919332  6493 net.cpp:226] relu5_3 needs backward computation.
I0713 17:35:54.919338  6493 net.cpp:226] conv5_3 needs backward computation.
I0713 17:35:54.919345  6493 net.cpp:226] relu5_2 needs backward computation.
I0713 17:35:54.919353  6493 net.cpp:226] conv5_2 needs backward computation.
I0713 17:35:54.919359  6493 net.cpp:226] relu5_1 needs backward computation.
I0713 17:35:54.919366  6493 net.cpp:226] conv5_1 needs backward computation.
I0713 17:35:54.919373  6493 net.cpp:226] pool4 needs backward computation.
I0713 17:35:54.919379  6493 net.cpp:226] relu4_3 needs backward computation.
I0713 17:35:54.919385  6493 net.cpp:226] conv4_3 needs backward computation.
I0713 17:35:54.919392  6493 net.cpp:226] relu4_2 needs backward computation.
I0713 17:35:54.919399  6493 net.cpp:226] conv4_2 needs backward computation.
I0713 17:35:54.919405  6493 net.cpp:226] relu4_1 needs backward computation.
I0713 17:35:54.919411  6493 net.cpp:226] conv4_1 needs backward computation.
I0713 17:35:54.919419  6493 net.cpp:226] pool3 needs backward computation.
I0713 17:35:54.919426  6493 net.cpp:226] relu3_3 needs backward computation.
I0713 17:35:54.919432  6493 net.cpp:226] conv3_3 needs backward computation.
I0713 17:35:54.919440  6493 net.cpp:226] relu3_2 needs backward computation.
I0713 17:35:54.919445  6493 net.cpp:226] conv3_2 needs backward computation.
I0713 17:35:54.919453  6493 net.cpp:226] relu3_1 needs backward computation.
I0713 17:35:54.919459  6493 net.cpp:226] conv3_1 needs backward computation.
I0713 17:35:54.919466  6493 net.cpp:226] pool2 needs backward computation.
I0713 17:35:54.919473  6493 net.cpp:226] relu2_2 needs backward computation.
I0713 17:35:54.919479  6493 net.cpp:226] conv2_2 needs backward computation.
I0713 17:35:54.919486  6493 net.cpp:226] relu2_1 needs backward computation.
I0713 17:35:54.919493  6493 net.cpp:226] conv2_1 needs backward computation.
I0713 17:35:54.919500  6493 net.cpp:226] pool1 needs backward computation.
I0713 17:35:54.919507  6493 net.cpp:226] relu1_2 needs backward computation.
I0713 17:35:54.919513  6493 net.cpp:226] conv1_2 needs backward computation.
I0713 17:35:54.919520  6493 net.cpp:226] relu1_1 needs backward computation.
I0713 17:35:54.919526  6493 net.cpp:226] conv1_1 needs backward computation.
I0713 17:35:54.919534  6493 net.cpp:228] data does not need backward computation.
I0713 17:35:54.919540  6493 net.cpp:270] This network produces output loss
I0713 17:35:54.919581  6493 net.cpp:283] Network initialization done.
I0713 17:35:54.921103  6493 solver.cpp:188] Creating test net (#0) specified by net file: examples/DPN_VOC/DPN_VOC.prototxt
I0713 17:35:54.921198  6493 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0713 17:35:54.921589  6493 net.cpp:58] Initializing net from parameters: 
name: "DPN"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "ImageSegData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 480
    mean_value: 104.00699
    mean_value: 116.66877
    mean_value: 122.67892
    label_crop_size: 96
  }
  image_data_param {
    source: "data/VOC_arg/val.txt"
    batch_size: 2
    shuffle: false
    root_folder: "data/VOC_arg"
    label_type: PIXEL
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 2
    kernel_size: 3
    dilation: 2
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "pool5a"
  type: "Pooling"
  bottom: "pool5"
  top: "pool5a"
  pooling_param {
    pool: AVE
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6-conv"
  type: "Convolution"
  bottom: "pool5a"
  top: "fc6-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 7
    dilation: 4
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6-conv"
  top: "fc6-conv"
}
layer {
  name: "drop6"
  type: "Dropout"
  bottom: "fc6-conv"
  top: "fc6-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc7-conv"
  type: "Convolution"
  bottom: "fc6-conv"
  top: "fc7-conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    kernel_size: 1
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7-conv"
  top: "fc7-conv"
}
layer {
  name: "drop7"
  type: "Dropout"
  bottom: "fc7-conv"
  top: "fc7-conv"
  dropout_param {
    dropout_ratio: 0.5
  }
}
layer {
  name: "fc8-VOC"
  type: "Convolution"
  bottom: "fc7-conv"
  top: "fc8-VOC"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 21
    kernel_size: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "upscore2"
  type: "Deconvolution"
  bottom: "fc8-VOC"
  top: "upscore"
  param {
    lr_mult: 0
  }
  convolution_param {
    num_output: 21
    bias_term: false
    pad: 4
    kernel_size: 16
    group: 21
    stride: 8
    weight_filler {
      type: "bilinear"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "upscore"
  bottom: "label"
  top: "loss"
  loss_param {
    ignore_label: 255
    hm_ratio: 0.5
  }
}
I0713 17:35:54.921818  6493 layer_factory.hpp:77] Creating layer data
I0713 17:35:54.921857  6493 net.cpp:100] Creating Layer data
I0713 17:35:54.921869  6493 net.cpp:408] data -> data
I0713 17:35:54.921886  6493 net.cpp:408] data -> label
I0713 17:35:54.921905  6493 image_seg_data_layer.cpp:45] Opening file data/VOC_arg/val.txt
I0713 17:35:54.924643  6493 image_seg_data_layer.cpp:106] A total of 1449 images.
I0713 17:35:54.927793  6493 image_seg_data_layer.cpp:179] output data size: 2,3,480,480
I0713 17:35:54.927810  6493 image_seg_data_layer.cpp:183] output label size: 2,1,288,288
I0713 17:35:54.944731  6493 net.cpp:150] Setting up data
I0713 17:35:54.944869  6493 net.cpp:157] Top shape: 2 3 480 480 (1382400)
I0713 17:35:54.944886  6493 net.cpp:157] Top shape: 2 1 288 288 (165888)
I0713 17:35:54.944893  6493 net.cpp:165] Memory required for data: 6193152
I0713 17:35:54.944908  6493 layer_factory.hpp:77] Creating layer conv1_1
I0713 17:35:54.944941  6493 net.cpp:100] Creating Layer conv1_1
I0713 17:35:54.944948  6493 net.cpp:434] conv1_1 <- data
I0713 17:35:54.944964  6493 net.cpp:408] conv1_1 -> conv1_1
I0713 17:35:54.947201  6493 net.cpp:150] Setting up conv1_1
I0713 17:35:54.947228  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.947237  6493 net.cpp:165] Memory required for data: 124157952
I0713 17:35:54.947257  6493 layer_factory.hpp:77] Creating layer relu1_1
I0713 17:35:54.947273  6493 net.cpp:100] Creating Layer relu1_1
I0713 17:35:54.947283  6493 net.cpp:434] relu1_1 <- conv1_1
I0713 17:35:54.947293  6493 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0713 17:35:54.947306  6493 net.cpp:150] Setting up relu1_1
I0713 17:35:54.947315  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.947321  6493 net.cpp:165] Memory required for data: 242122752
I0713 17:35:54.947327  6493 layer_factory.hpp:77] Creating layer conv1_2
I0713 17:35:54.947341  6493 net.cpp:100] Creating Layer conv1_2
I0713 17:35:54.947347  6493 net.cpp:434] conv1_2 <- conv1_1
I0713 17:35:54.947358  6493 net.cpp:408] conv1_2 -> conv1_2
I0713 17:35:54.951216  6493 net.cpp:150] Setting up conv1_2
I0713 17:35:54.951270  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.951278  6493 net.cpp:165] Memory required for data: 360087552
I0713 17:35:54.951308  6493 layer_factory.hpp:77] Creating layer relu1_2
I0713 17:35:54.951330  6493 net.cpp:100] Creating Layer relu1_2
I0713 17:35:54.951340  6493 net.cpp:434] relu1_2 <- conv1_2
I0713 17:35:54.951355  6493 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0713 17:35:54.951375  6493 net.cpp:150] Setting up relu1_2
I0713 17:35:54.951385  6493 net.cpp:157] Top shape: 2 64 480 480 (29491200)
I0713 17:35:54.951392  6493 net.cpp:165] Memory required for data: 478052352
I0713 17:35:54.951398  6493 layer_factory.hpp:77] Creating layer pool1
I0713 17:35:54.951411  6493 net.cpp:100] Creating Layer pool1
I0713 17:35:54.951418  6493 net.cpp:434] pool1 <- conv1_2
I0713 17:35:54.951428  6493 net.cpp:408] pool1 -> pool1
I0713 17:35:54.952373  6493 net.cpp:150] Setting up pool1
I0713 17:35:54.952399  6493 net.cpp:157] Top shape: 2 64 240 240 (7372800)
I0713 17:35:54.952407  6493 net.cpp:165] Memory required for data: 507543552
I0713 17:35:54.952415  6493 layer_factory.hpp:77] Creating layer conv2_1
I0713 17:35:54.952436  6493 net.cpp:100] Creating Layer conv2_1
I0713 17:35:54.952445  6493 net.cpp:434] conv2_1 <- pool1
I0713 17:35:54.952458  6493 net.cpp:408] conv2_1 -> conv2_1
I0713 17:35:54.952925  6493 net.cpp:150] Setting up conv2_1
I0713 17:35:54.952944  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.952950  6493 net.cpp:165] Memory required for data: 566525952
I0713 17:35:54.952967  6493 layer_factory.hpp:77] Creating layer relu2_1
I0713 17:35:54.952981  6493 net.cpp:100] Creating Layer relu2_1
I0713 17:35:54.952991  6493 net.cpp:434] relu2_1 <- conv2_1
I0713 17:35:54.953001  6493 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0713 17:35:54.953014  6493 net.cpp:150] Setting up relu2_1
I0713 17:35:54.953023  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.953029  6493 net.cpp:165] Memory required for data: 625508352
I0713 17:35:54.953037  6493 layer_factory.hpp:77] Creating layer conv2_2
I0713 17:35:54.953052  6493 net.cpp:100] Creating Layer conv2_2
I0713 17:35:54.953058  6493 net.cpp:434] conv2_2 <- conv2_1
I0713 17:35:54.953070  6493 net.cpp:408] conv2_2 -> conv2_2
I0713 17:35:54.955559  6493 net.cpp:150] Setting up conv2_2
I0713 17:35:54.955581  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.955590  6493 net.cpp:165] Memory required for data: 684490752
I0713 17:35:54.955601  6493 layer_factory.hpp:77] Creating layer relu2_2
I0713 17:35:54.955657  6493 net.cpp:100] Creating Layer relu2_2
I0713 17:35:54.955665  6493 net.cpp:434] relu2_2 <- conv2_2
I0713 17:35:54.955675  6493 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0713 17:35:54.955688  6493 net.cpp:150] Setting up relu2_2
I0713 17:35:54.955698  6493 net.cpp:157] Top shape: 2 128 240 240 (14745600)
I0713 17:35:54.955704  6493 net.cpp:165] Memory required for data: 743473152
I0713 17:35:54.955710  6493 layer_factory.hpp:77] Creating layer pool2
I0713 17:35:54.955721  6493 net.cpp:100] Creating Layer pool2
I0713 17:35:54.955729  6493 net.cpp:434] pool2 <- conv2_2
I0713 17:35:54.955739  6493 net.cpp:408] pool2 -> pool2
I0713 17:35:54.960677  6493 net.cpp:150] Setting up pool2
I0713 17:35:54.960741  6493 net.cpp:157] Top shape: 2 128 120 120 (3686400)
I0713 17:35:54.960750  6493 net.cpp:165] Memory required for data: 758218752
I0713 17:35:54.960762  6493 layer_factory.hpp:77] Creating layer conv3_1
I0713 17:35:54.960796  6493 net.cpp:100] Creating Layer conv3_1
I0713 17:35:54.960806  6493 net.cpp:434] conv3_1 <- pool2
I0713 17:35:54.960827  6493 net.cpp:408] conv3_1 -> conv3_1
I0713 17:35:54.962494  6493 net.cpp:150] Setting up conv3_1
I0713 17:35:54.962534  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.962543  6493 net.cpp:165] Memory required for data: 787709952
I0713 17:35:54.962564  6493 layer_factory.hpp:77] Creating layer relu3_1
I0713 17:35:54.962582  6493 net.cpp:100] Creating Layer relu3_1
I0713 17:35:54.962599  6493 net.cpp:434] relu3_1 <- conv3_1
I0713 17:35:54.962610  6493 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0713 17:35:54.962625  6493 net.cpp:150] Setting up relu3_1
I0713 17:35:54.962635  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.962641  6493 net.cpp:165] Memory required for data: 817201152
I0713 17:35:54.962647  6493 layer_factory.hpp:77] Creating layer conv3_2
I0713 17:35:54.962663  6493 net.cpp:100] Creating Layer conv3_2
I0713 17:35:54.962671  6493 net.cpp:434] conv3_2 <- conv3_1
I0713 17:35:54.962682  6493 net.cpp:408] conv3_2 -> conv3_2
I0713 17:35:54.965714  6493 net.cpp:150] Setting up conv3_2
I0713 17:35:54.965754  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.965760  6493 net.cpp:165] Memory required for data: 846692352
I0713 17:35:54.965777  6493 layer_factory.hpp:77] Creating layer relu3_2
I0713 17:35:54.965808  6493 net.cpp:100] Creating Layer relu3_2
I0713 17:35:54.965816  6493 net.cpp:434] relu3_2 <- conv3_2
I0713 17:35:54.965831  6493 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0713 17:35:54.965848  6493 net.cpp:150] Setting up relu3_2
I0713 17:35:54.965857  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.965863  6493 net.cpp:165] Memory required for data: 876183552
I0713 17:35:54.965870  6493 layer_factory.hpp:77] Creating layer conv3_3
I0713 17:35:54.965888  6493 net.cpp:100] Creating Layer conv3_3
I0713 17:35:54.965908  6493 net.cpp:434] conv3_3 <- conv3_2
I0713 17:35:54.965919  6493 net.cpp:408] conv3_3 -> conv3_3
I0713 17:35:54.968118  6493 net.cpp:150] Setting up conv3_3
I0713 17:35:54.968150  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.968158  6493 net.cpp:165] Memory required for data: 905674752
I0713 17:35:54.968171  6493 layer_factory.hpp:77] Creating layer relu3_3
I0713 17:35:54.968192  6493 net.cpp:100] Creating Layer relu3_3
I0713 17:35:54.968201  6493 net.cpp:434] relu3_3 <- conv3_3
I0713 17:35:54.968219  6493 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0713 17:35:54.968231  6493 net.cpp:150] Setting up relu3_3
I0713 17:35:54.968240  6493 net.cpp:157] Top shape: 2 256 120 120 (7372800)
I0713 17:35:54.968247  6493 net.cpp:165] Memory required for data: 935165952
I0713 17:35:54.968255  6493 layer_factory.hpp:77] Creating layer pool3
I0713 17:35:54.968267  6493 net.cpp:100] Creating Layer pool3
I0713 17:35:54.968274  6493 net.cpp:434] pool3 <- conv3_3
I0713 17:35:54.968286  6493 net.cpp:408] pool3 -> pool3
I0713 17:35:54.968348  6493 net.cpp:150] Setting up pool3
I0713 17:35:54.968369  6493 net.cpp:157] Top shape: 2 256 60 60 (1843200)
I0713 17:35:54.968420  6493 net.cpp:165] Memory required for data: 942538752
I0713 17:35:54.968431  6493 layer_factory.hpp:77] Creating layer conv4_1
I0713 17:35:54.968447  6493 net.cpp:100] Creating Layer conv4_1
I0713 17:35:54.968454  6493 net.cpp:434] conv4_1 <- pool3
I0713 17:35:54.968466  6493 net.cpp:408] conv4_1 -> conv4_1
I0713 17:35:54.972681  6493 net.cpp:150] Setting up conv4_1
I0713 17:35:54.972781  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.972798  6493 net.cpp:165] Memory required for data: 957284352
I0713 17:35:54.972815  6493 layer_factory.hpp:77] Creating layer relu4_1
I0713 17:35:54.972837  6493 net.cpp:100] Creating Layer relu4_1
I0713 17:35:54.972851  6493 net.cpp:434] relu4_1 <- conv4_1
I0713 17:35:54.972867  6493 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0713 17:35:54.972887  6493 net.cpp:150] Setting up relu4_1
I0713 17:35:54.972898  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.972904  6493 net.cpp:165] Memory required for data: 972029952
I0713 17:35:54.972911  6493 layer_factory.hpp:77] Creating layer conv4_2
I0713 17:35:54.972929  6493 net.cpp:100] Creating Layer conv4_2
I0713 17:35:54.972939  6493 net.cpp:434] conv4_2 <- conv4_1
I0713 17:35:54.972951  6493 net.cpp:408] conv4_2 -> conv4_2
I0713 17:35:54.981009  6493 net.cpp:150] Setting up conv4_2
I0713 17:35:54.981060  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.981068  6493 net.cpp:165] Memory required for data: 986775552
I0713 17:35:54.981097  6493 layer_factory.hpp:77] Creating layer relu4_2
I0713 17:35:54.981127  6493 net.cpp:100] Creating Layer relu4_2
I0713 17:35:54.981137  6493 net.cpp:434] relu4_2 <- conv4_2
I0713 17:35:54.981153  6493 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0713 17:35:54.981173  6493 net.cpp:150] Setting up relu4_2
I0713 17:35:54.981181  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.981187  6493 net.cpp:165] Memory required for data: 1001521152
I0713 17:35:54.981195  6493 layer_factory.hpp:77] Creating layer conv4_3
I0713 17:35:54.981211  6493 net.cpp:100] Creating Layer conv4_3
I0713 17:35:54.981225  6493 net.cpp:434] conv4_3 <- conv4_2
I0713 17:35:54.981236  6493 net.cpp:408] conv4_3 -> conv4_3
I0713 17:35:54.989471  6493 net.cpp:150] Setting up conv4_3
I0713 17:35:54.989553  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989562  6493 net.cpp:165] Memory required for data: 1016266752
I0713 17:35:54.989580  6493 layer_factory.hpp:77] Creating layer relu4_3
I0713 17:35:54.989610  6493 net.cpp:100] Creating Layer relu4_3
I0713 17:35:54.989621  6493 net.cpp:434] relu4_3 <- conv4_3
I0713 17:35:54.989637  6493 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0713 17:35:54.989656  6493 net.cpp:150] Setting up relu4_3
I0713 17:35:54.989665  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989672  6493 net.cpp:165] Memory required for data: 1031012352
I0713 17:35:54.989680  6493 layer_factory.hpp:77] Creating layer pool4
I0713 17:35:54.989694  6493 net.cpp:100] Creating Layer pool4
I0713 17:35:54.989707  6493 net.cpp:434] pool4 <- conv4_3
I0713 17:35:54.989718  6493 net.cpp:408] pool4 -> pool4
I0713 17:35:54.989783  6493 net.cpp:150] Setting up pool4
I0713 17:35:54.989800  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.989807  6493 net.cpp:165] Memory required for data: 1045757952
I0713 17:35:54.989814  6493 layer_factory.hpp:77] Creating layer conv5_1
I0713 17:35:54.989835  6493 net.cpp:100] Creating Layer conv5_1
I0713 17:35:54.989843  6493 net.cpp:434] conv5_1 <- pool4
I0713 17:35:54.989863  6493 net.cpp:408] conv5_1 -> conv5_1
I0713 17:35:54.998775  6493 net.cpp:150] Setting up conv5_1
I0713 17:35:54.998854  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.998863  6493 net.cpp:165] Memory required for data: 1060503552
I0713 17:35:54.998883  6493 layer_factory.hpp:77] Creating layer relu5_1
I0713 17:35:54.998914  6493 net.cpp:100] Creating Layer relu5_1
I0713 17:35:54.998924  6493 net.cpp:434] relu5_1 <- conv5_1
I0713 17:35:54.998939  6493 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0713 17:35:54.999009  6493 net.cpp:150] Setting up relu5_1
I0713 17:35:54.999020  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:54.999027  6493 net.cpp:165] Memory required for data: 1075249152
I0713 17:35:54.999033  6493 layer_factory.hpp:77] Creating layer conv5_2
I0713 17:35:54.999052  6493 net.cpp:100] Creating Layer conv5_2
I0713 17:35:54.999058  6493 net.cpp:434] conv5_2 <- conv5_1
I0713 17:35:54.999070  6493 net.cpp:408] conv5_2 -> conv5_2
I0713 17:35:55.007140  6493 net.cpp:150] Setting up conv5_2
I0713 17:35:55.007212  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.007220  6493 net.cpp:165] Memory required for data: 1089994752
I0713 17:35:55.007238  6493 layer_factory.hpp:77] Creating layer relu5_2
I0713 17:35:55.007259  6493 net.cpp:100] Creating Layer relu5_2
I0713 17:35:55.007271  6493 net.cpp:434] relu5_2 <- conv5_2
I0713 17:35:55.007287  6493 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0713 17:35:55.007308  6493 net.cpp:150] Setting up relu5_2
I0713 17:35:55.007319  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.007326  6493 net.cpp:165] Memory required for data: 1104740352
I0713 17:35:55.007333  6493 layer_factory.hpp:77] Creating layer conv5_3
I0713 17:35:55.007350  6493 net.cpp:100] Creating Layer conv5_3
I0713 17:35:55.007359  6493 net.cpp:434] conv5_3 <- conv5_2
I0713 17:35:55.007372  6493 net.cpp:408] conv5_3 -> conv5_3
I0713 17:35:55.015444  6493 net.cpp:150] Setting up conv5_3
I0713 17:35:55.015511  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015519  6493 net.cpp:165] Memory required for data: 1119485952
I0713 17:35:55.015537  6493 layer_factory.hpp:77] Creating layer relu5_3
I0713 17:35:55.015558  6493 net.cpp:100] Creating Layer relu5_3
I0713 17:35:55.015568  6493 net.cpp:434] relu5_3 <- conv5_3
I0713 17:35:55.015584  6493 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0713 17:35:55.015604  6493 net.cpp:150] Setting up relu5_3
I0713 17:35:55.015612  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015619  6493 net.cpp:165] Memory required for data: 1134231552
I0713 17:35:55.015626  6493 layer_factory.hpp:77] Creating layer pool5
I0713 17:35:55.015640  6493 net.cpp:100] Creating Layer pool5
I0713 17:35:55.015653  6493 net.cpp:434] pool5 <- conv5_3
I0713 17:35:55.015664  6493 net.cpp:408] pool5 -> pool5
I0713 17:35:55.015730  6493 net.cpp:150] Setting up pool5
I0713 17:35:55.015744  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015751  6493 net.cpp:165] Memory required for data: 1148977152
I0713 17:35:55.015758  6493 layer_factory.hpp:77] Creating layer pool5a
I0713 17:35:55.015779  6493 net.cpp:100] Creating Layer pool5a
I0713 17:35:55.015786  6493 net.cpp:434] pool5a <- pool5
I0713 17:35:55.015797  6493 net.cpp:408] pool5a -> pool5a
I0713 17:35:55.015835  6493 net.cpp:150] Setting up pool5a
I0713 17:35:55.015847  6493 net.cpp:157] Top shape: 2 512 60 60 (3686400)
I0713 17:35:55.015854  6493 net.cpp:165] Memory required for data: 1163722752
I0713 17:35:55.015861  6493 layer_factory.hpp:77] Creating layer fc6-conv
I0713 17:35:55.015879  6493 net.cpp:100] Creating Layer fc6-conv
I0713 17:35:55.015887  6493 net.cpp:434] fc6-conv <- pool5a
I0713 17:35:55.015898  6493 net.cpp:408] fc6-conv -> fc6-conv
I0713 17:35:55.333092  6493 net.cpp:150] Setting up fc6-conv
I0713 17:35:55.333170  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333179  6493 net.cpp:165] Memory required for data: 1206190080
I0713 17:35:55.333223  6493 layer_factory.hpp:77] Creating layer relu6
I0713 17:35:55.333284  6493 net.cpp:100] Creating Layer relu6
I0713 17:35:55.333317  6493 net.cpp:434] relu6 <- fc6-conv
I0713 17:35:55.333334  6493 net.cpp:395] relu6 -> fc6-conv (in-place)
I0713 17:35:55.333353  6493 net.cpp:150] Setting up relu6
I0713 17:35:55.333361  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333369  6493 net.cpp:165] Memory required for data: 1248657408
I0713 17:35:55.333374  6493 layer_factory.hpp:77] Creating layer drop6
I0713 17:35:55.333395  6493 net.cpp:100] Creating Layer drop6
I0713 17:35:55.333431  6493 net.cpp:434] drop6 <- fc6-conv
I0713 17:35:55.333442  6493 net.cpp:395] drop6 -> fc6-conv (in-place)
I0713 17:35:55.333487  6493 net.cpp:150] Setting up drop6
I0713 17:35:55.333501  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.333508  6493 net.cpp:165] Memory required for data: 1291124736
I0713 17:35:55.333515  6493 layer_factory.hpp:77] Creating layer fc7-conv
I0713 17:35:55.333545  6493 net.cpp:100] Creating Layer fc7-conv
I0713 17:35:55.333554  6493 net.cpp:434] fc7-conv <- fc6-conv
I0713 17:35:55.333564  6493 net.cpp:408] fc7-conv -> fc7-conv
I0713 17:35:55.383952  6493 net.cpp:150] Setting up fc7-conv
I0713 17:35:55.384017  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384027  6493 net.cpp:165] Memory required for data: 1333592064
I0713 17:35:55.384043  6493 layer_factory.hpp:77] Creating layer relu7
I0713 17:35:55.384080  6493 net.cpp:100] Creating Layer relu7
I0713 17:35:55.384091  6493 net.cpp:434] relu7 <- fc7-conv
I0713 17:35:55.384106  6493 net.cpp:395] relu7 -> fc7-conv (in-place)
I0713 17:35:55.384124  6493 net.cpp:150] Setting up relu7
I0713 17:35:55.384133  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384140  6493 net.cpp:165] Memory required for data: 1376059392
I0713 17:35:55.384146  6493 layer_factory.hpp:77] Creating layer drop7
I0713 17:35:55.384166  6493 net.cpp:100] Creating Layer drop7
I0713 17:35:55.384174  6493 net.cpp:434] drop7 <- fc7-conv
I0713 17:35:55.384184  6493 net.cpp:395] drop7 -> fc7-conv (in-place)
I0713 17:35:55.384227  6493 net.cpp:150] Setting up drop7
I0713 17:35:55.384239  6493 net.cpp:157] Top shape: 2 4096 36 36 (10616832)
I0713 17:35:55.384246  6493 net.cpp:165] Memory required for data: 1418526720
I0713 17:35:55.384253  6493 layer_factory.hpp:77] Creating layer fc8-VOC
I0713 17:35:55.384271  6493 net.cpp:100] Creating Layer fc8-VOC
I0713 17:35:55.384279  6493 net.cpp:434] fc8-VOC <- fc7-conv
I0713 17:35:55.384294  6493 net.cpp:408] fc8-VOC -> fc8-VOC
I0713 17:35:55.388170  6493 net.cpp:150] Setting up fc8-VOC
I0713 17:35:55.388190  6493 net.cpp:157] Top shape: 2 21 36 36 (54432)
I0713 17:35:55.388197  6493 net.cpp:165] Memory required for data: 1418744448
I0713 17:35:55.388209  6493 layer_factory.hpp:77] Creating layer upscore2
I0713 17:35:55.388223  6493 net.cpp:100] Creating Layer upscore2
I0713 17:35:55.388231  6493 net.cpp:434] upscore2 <- fc8-VOC
I0713 17:35:55.388242  6493 net.cpp:408] upscore2 -> upscore
I0713 17:35:55.388895  6493 net.cpp:150] Setting up upscore2
I0713 17:35:55.388912  6493 net.cpp:157] Top shape: 2 21 288 288 (3483648)
I0713 17:35:55.388919  6493 net.cpp:165] Memory required for data: 1432679040
I0713 17:35:55.388947  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:55.388975  6493 net.cpp:100] Creating Layer loss
I0713 17:35:55.388988  6493 net.cpp:434] loss <- upscore
I0713 17:35:55.388996  6493 net.cpp:434] loss <- label
I0713 17:35:55.389008  6493 net.cpp:408] loss -> loss
I0713 17:35:55.389024  6493 layer_factory.hpp:77] Creating layer loss
I0713 17:35:55.400105  6493 net.cpp:150] Setting up loss
I0713 17:35:55.400159  6493 net.cpp:157] Top shape: (1)
I0713 17:35:55.400167  6493 net.cpp:160]     with loss weight 1
I0713 17:35:55.400223  6493 net.cpp:165] Memory required for data: 1432679044
I0713 17:35:55.400235  6493 net.cpp:226] loss needs backward computation.
I0713 17:35:55.400244  6493 net.cpp:226] upscore2 needs backward computation.
I0713 17:35:55.400252  6493 net.cpp:226] fc8-VOC needs backward computation.
I0713 17:35:55.400259  6493 net.cpp:226] drop7 needs backward computation.
I0713 17:35:55.400265  6493 net.cpp:226] relu7 needs backward computation.
I0713 17:35:55.400272  6493 net.cpp:226] fc7-conv needs backward computation.
I0713 17:35:55.400279  6493 net.cpp:226] drop6 needs backward computation.
I0713 17:35:55.400285  6493 net.cpp:226] relu6 needs backward computation.
I0713 17:35:55.400291  6493 net.cpp:226] fc6-conv needs backward computation.
I0713 17:35:55.400298  6493 net.cpp:226] pool5a needs backward computation.
I0713 17:35:55.400342  6493 net.cpp:226] pool5 needs backward computation.
I0713 17:35:55.400352  6493 net.cpp:226] relu5_3 needs backward computation.
I0713 17:35:55.400359  6493 net.cpp:226] conv5_3 needs backward computation.
I0713 17:35:55.400367  6493 net.cpp:226] relu5_2 needs backward computation.
I0713 17:35:55.400382  6493 net.cpp:226] conv5_2 needs backward computation.
I0713 17:35:55.400388  6493 net.cpp:226] relu5_1 needs backward computation.
I0713 17:35:55.400404  6493 net.cpp:226] conv5_1 needs backward computation.
I0713 17:35:55.400419  6493 net.cpp:226] pool4 needs backward computation.
I0713 17:35:55.400426  6493 net.cpp:226] relu4_3 needs backward computation.
I0713 17:35:55.400434  6493 net.cpp:226] conv4_3 needs backward computation.
I0713 17:35:55.400440  6493 net.cpp:226] relu4_2 needs backward computation.
I0713 17:35:55.400447  6493 net.cpp:226] conv4_2 needs backward computation.
I0713 17:35:55.400454  6493 net.cpp:226] relu4_1 needs backward computation.
I0713 17:35:55.400460  6493 net.cpp:226] conv4_1 needs backward computation.
I0713 17:35:55.400466  6493 net.cpp:226] pool3 needs backward computation.
I0713 17:35:55.400473  6493 net.cpp:226] relu3_3 needs backward computation.
I0713 17:35:55.400480  6493 net.cpp:226] conv3_3 needs backward computation.
I0713 17:35:55.400485  6493 net.cpp:226] relu3_2 needs backward computation.
I0713 17:35:55.400491  6493 net.cpp:226] conv3_2 needs backward computation.
I0713 17:35:55.400498  6493 net.cpp:226] relu3_1 needs backward computation.
I0713 17:35:55.400506  6493 net.cpp:226] conv3_1 needs backward computation.
I0713 17:35:55.400512  6493 net.cpp:226] pool2 needs backward computation.
I0713 17:35:55.400518  6493 net.cpp:226] relu2_2 needs backward computation.
I0713 17:35:55.400526  6493 net.cpp:226] conv2_2 needs backward computation.
I0713 17:35:55.400532  6493 net.cpp:226] relu2_1 needs backward computation.
I0713 17:35:55.400538  6493 net.cpp:226] conv2_1 needs backward computation.
I0713 17:35:55.400558  6493 net.cpp:226] pool1 needs backward computation.
I0713 17:35:55.400566  6493 net.cpp:226] relu1_2 needs backward computation.
I0713 17:35:55.400573  6493 net.cpp:226] conv1_2 needs backward computation.
I0713 17:35:55.400578  6493 net.cpp:226] relu1_1 needs backward computation.
I0713 17:35:55.400588  6493 net.cpp:226] conv1_1 needs backward computation.
I0713 17:35:55.400595  6493 net.cpp:228] data does not need backward computation.
I0713 17:35:55.400601  6493 net.cpp:270] This network produces output loss
I0713 17:35:55.400640  6493 net.cpp:283] Network initialization done.
I0713 17:35:55.401125  6493 solver.cpp:63] Solver scaffolding done.
I0713 17:35:55.507159  6493 solver.cpp:68] Pavi init done.
I0713 17:35:55.509263  6493 caffe.cpp:155] Finetuning from examples/DPN_VOC/VGG_16.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537843972
I0713 17:35:56.714289  6493 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/DPN_VOC/VGG_16.caffemodel
I0713 17:35:56.714351  6493 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0713 17:35:56.714361  6493 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0713 17:35:56.722481  6493 net.cpp:761] Ignoring source layer split4
I0713 17:35:56.724892  6493 net.cpp:761] Ignoring source layer relu5_1_1
I0713 17:35:56.724952  6493 net.cpp:761] Ignoring source layer relu5_1_2
I0713 17:35:56.724959  6493 net.cpp:761] Ignoring source layer relu5_1_3
I0713 17:35:56.724966  6493 net.cpp:761] Ignoring source layer relu5_1_4
I0713 17:35:56.727246  6493 net.cpp:761] Ignoring source layer relu5_2_1
I0713 17:35:56.727309  6493 net.cpp:761] Ignoring source layer relu5_2_2
I0713 17:35:56.727316  6493 net.cpp:761] Ignoring source layer relu5_2_3
I0713 17:35:56.727322  6493 net.cpp:761] Ignoring source layer relu5_2_4
I0713 17:35:56.729638  6493 net.cpp:761] Ignoring source layer relu5_3_1
I0713 17:35:56.729698  6493 net.cpp:761] Ignoring source layer relu5_3_2
I0713 17:35:56.729704  6493 net.cpp:761] Ignoring source layer relu5_3_3
I0713 17:35:56.729764  6493 net.cpp:761] Ignoring source layer relu5_3_4
I0713 17:35:56.729773  6493 net.cpp:761] Ignoring source layer split5_1
I0713 17:35:56.729779  6493 net.cpp:761] Ignoring source layer split5_2
I0713 17:35:56.729790  6493 net.cpp:761] Ignoring source layer split5_3
I0713 17:35:56.729797  6493 net.cpp:761] Ignoring source layer split5_4
I0713 17:35:56.855729  6493 net.cpp:761] Ignoring source layer relu6_1
I0713 17:35:56.855787  6493 net.cpp:761] Ignoring source layer relu6_2
I0713 17:35:56.855795  6493 net.cpp:761] Ignoring source layer relu6_3
I0713 17:35:56.855801  6493 net.cpp:761] Ignoring source layer relu6_4
I0713 17:35:56.855808  6493 net.cpp:761] Ignoring source layer relu6_5
I0713 17:35:56.855813  6493 net.cpp:761] Ignoring source layer relu6_6
I0713 17:35:56.855819  6493 net.cpp:761] Ignoring source layer relu6_7
I0713 17:35:56.855825  6493 net.cpp:761] Ignoring source layer relu6_8
I0713 17:35:56.855830  6493 net.cpp:761] Ignoring source layer relu6_9
I0713 17:35:56.855841  6493 net.cpp:761] Ignoring source layer relu6_10
I0713 17:35:56.855852  6493 net.cpp:761] Ignoring source layer relu6_11
I0713 17:35:56.855859  6493 net.cpp:761] Ignoring source layer relu6_12
I0713 17:35:56.855864  6493 net.cpp:761] Ignoring source layer relu6_13
I0713 17:35:56.855870  6493 net.cpp:761] Ignoring source layer relu6_14
I0713 17:35:56.855875  6493 net.cpp:761] Ignoring source layer relu6_15
I0713 17:35:56.855880  6493 net.cpp:761] Ignoring source layer relu6_16
I0713 17:35:56.877863  6493 net.cpp:761] Ignoring source layer relu7_1
I0713 17:35:56.877907  6493 net.cpp:761] Ignoring source layer relu7_2
I0713 17:35:56.877913  6493 net.cpp:761] Ignoring source layer relu7_3
I0713 17:35:56.877919  6493 net.cpp:761] Ignoring source layer relu7_4
I0713 17:35:56.877925  6493 net.cpp:761] Ignoring source layer relu7_5
I0713 17:35:56.877931  6493 net.cpp:761] Ignoring source layer relu7_6
I0713 17:35:56.877938  6493 net.cpp:761] Ignoring source layer relu7_7
I0713 17:35:56.877943  6493 net.cpp:761] Ignoring source layer relu7_8
I0713 17:35:56.877948  6493 net.cpp:761] Ignoring source layer relu7_9
I0713 17:35:56.877955  6493 net.cpp:761] Ignoring source layer relu7_10
I0713 17:35:56.877961  6493 net.cpp:761] Ignoring source layer relu7_11
I0713 17:35:56.877970  6493 net.cpp:761] Ignoring source layer relu7_12
I0713 17:35:56.877975  6493 net.cpp:761] Ignoring source layer relu7_13
I0713 17:35:56.877981  6493 net.cpp:761] Ignoring source layer relu7_14
I0713 17:35:56.877986  6493 net.cpp:761] Ignoring source layer relu7_15
I0713 17:35:56.877991  6493 net.cpp:761] Ignoring source layer relu7_16
I0713 17:35:56.877997  6493 net.cpp:761] Ignoring source layer fc8-conv_21
I0713 17:35:56.878003  6493 net.cpp:761] Ignoring source layer split6
I0713 17:35:56.878010  6493 net.cpp:761] Ignoring source layer upscore
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:505] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:78] The total number of bytes read was 537843972
I0713 17:35:58.069021  6493 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/DPN_VOC/VGG_16.caffemodel
I0713 17:35:58.069077  6493 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0713 17:35:58.069084  6493 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0713 17:35:58.085005  6493 net.cpp:761] Ignoring source layer split4
I0713 17:35:58.088013  6493 net.cpp:761] Ignoring source layer relu5_1_1
I0713 17:35:58.088054  6493 net.cpp:761] Ignoring source layer relu5_1_2
I0713 17:35:58.088063  6493 net.cpp:761] Ignoring source layer relu5_1_3
I0713 17:35:58.088069  6493 net.cpp:761] Ignoring source layer relu5_1_4
I0713 17:35:58.091111  6493 net.cpp:761] Ignoring source layer relu5_2_1
I0713 17:35:58.091153  6493 net.cpp:761] Ignoring source layer relu5_2_2
I0713 17:35:58.091161  6493 net.cpp:761] Ignoring source layer relu5_2_3
I0713 17:35:58.091166  6493 net.cpp:761] Ignoring source layer relu5_2_4
I0713 17:35:58.094200  6493 net.cpp:761] Ignoring source layer relu5_3_1
I0713 17:35:58.094238  6493 net.cpp:761] Ignoring source layer relu5_3_2
I0713 17:35:58.094287  6493 net.cpp:761] Ignoring source layer relu5_3_3
I0713 17:35:58.094295  6493 net.cpp:761] Ignoring source layer relu5_3_4
I0713 17:35:58.094301  6493 net.cpp:761] Ignoring source layer split5_1
I0713 17:35:58.094307  6493 net.cpp:761] Ignoring source layer split5_2
I0713 17:35:58.094312  6493 net.cpp:761] Ignoring source layer split5_3
I0713 17:35:58.094323  6493 net.cpp:761] Ignoring source layer split5_4
I0713 17:35:58.209172  6493 net.cpp:761] Ignoring source layer relu6_1
I0713 17:35:58.209236  6493 net.cpp:761] Ignoring source layer relu6_2
I0713 17:35:58.209245  6493 net.cpp:761] Ignoring source layer relu6_3
I0713 17:35:58.209251  6493 net.cpp:761] Ignoring source layer relu6_4
I0713 17:35:58.209257  6493 net.cpp:761] Ignoring source layer relu6_5
I0713 17:35:58.209264  6493 net.cpp:761] Ignoring source layer relu6_6
I0713 17:35:58.209270  6493 net.cpp:761] Ignoring source layer relu6_7
I0713 17:35:58.209276  6493 net.cpp:761] Ignoring source layer relu6_8
I0713 17:35:58.209282  6493 net.cpp:761] Ignoring source layer relu6_9
I0713 17:35:58.209288  6493 net.cpp:761] Ignoring source layer relu6_10
I0713 17:35:58.209295  6493 net.cpp:761] Ignoring source layer relu6_11
I0713 17:35:58.209300  6493 net.cpp:761] Ignoring source layer relu6_12
I0713 17:35:58.209306  6493 net.cpp:761] Ignoring source layer relu6_13
I0713 17:35:58.209311  6493 net.cpp:761] Ignoring source layer relu6_14
I0713 17:35:58.209317  6493 net.cpp:761] Ignoring source layer relu6_15
I0713 17:35:58.209322  6493 net.cpp:761] Ignoring source layer relu6_16
I0713 17:35:58.228015  6493 net.cpp:761] Ignoring source layer relu7_1
I0713 17:35:58.228063  6493 net.cpp:761] Ignoring source layer relu7_2
I0713 17:35:58.228070  6493 net.cpp:761] Ignoring source layer relu7_3
I0713 17:35:58.228077  6493 net.cpp:761] Ignoring source layer relu7_4
I0713 17:35:58.228083  6493 net.cpp:761] Ignoring source layer relu7_5
I0713 17:35:58.228090  6493 net.cpp:761] Ignoring source layer relu7_6
I0713 17:35:58.228097  6493 net.cpp:761] Ignoring source layer relu7_7
I0713 17:35:58.228103  6493 net.cpp:761] Ignoring source layer relu7_8
I0713 17:35:58.228111  6493 net.cpp:761] Ignoring source layer relu7_9
I0713 17:35:58.228116  6493 net.cpp:761] Ignoring source layer relu7_10
I0713 17:35:58.228121  6493 net.cpp:761] Ignoring source layer relu7_11
I0713 17:35:58.228127  6493 net.cpp:761] Ignoring source layer relu7_12
I0713 17:35:58.228133  6493 net.cpp:761] Ignoring source layer relu7_13
I0713 17:35:58.228139  6493 net.cpp:761] Ignoring source layer relu7_14
I0713 17:35:58.228145  6493 net.cpp:761] Ignoring source layer relu7_15
I0713 17:35:58.228150  6493 net.cpp:761] Ignoring source layer relu7_16
I0713 17:35:58.228157  6493 net.cpp:761] Ignoring source layer fc8-conv_21
I0713 17:35:58.228163  6493 net.cpp:761] Ignoring source layer split6
I0713 17:35:58.228169  6493 net.cpp:761] Ignoring source layer upscore
I0713 17:35:58.233036  6493 caffe.cpp:251] Starting Optimization
I0713 17:35:58.233086  6493 solver.cpp:294] Solving DPN
I0713 17:35:58.233096  6493 solver.cpp:295] Learning Rate Policy: step
I0713 17:35:58.237236  6493 solver.cpp:352] Iteration 0, Testing net (#0)
I0713 17:39:08.359921  6493 solver.cpp:419]     Test net output #0: loss = 3.81606 (* 1 = 3.81606 loss)
I0713 17:39:09.793334  6493 solver.cpp:235] Iteration 0, loss = 4.13121
I0713 17:39:09.793568  6493 solver.cpp:255]     Train net output #0: loss = 4.13121 (* 1 = 4.13121 loss)
I0713 17:39:09.793853  6493 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0713 17:39:57.378682  6493 solver.cpp:235] Iteration 10, loss = 2.56187
I0713 17:39:57.379040  6493 solver.cpp:255]     Train net output #0: loss = 2.56187 (* 1 = 2.56187 loss)
I0713 17:39:57.379323  6493 sgd_solver.cpp:106] Iteration 10, lr = 0.001
I0713 17:40:44.975020  6493 solver.cpp:235] Iteration 20, loss = 2.35665
I0713 17:40:44.975419  6493 solver.cpp:255]     Train net output #0: loss = 2.35665 (* 1 = 2.35665 loss)
I0713 17:40:44.975664  6493 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0713 17:41:32.499617  6493 solver.cpp:235] Iteration 30, loss = 1.88635
I0713 17:41:32.499909  6493 solver.cpp:255]     Train net output #0: loss = 1.88635 (* 1 = 1.88635 loss)
I0713 17:41:32.500028  6493 sgd_solver.cpp:106] Iteration 30, lr = 0.001
I0713 17:42:20.059455  6493 solver.cpp:235] Iteration 40, loss = 1.29347
I0713 17:42:20.059921  6493 solver.cpp:255]     Train net output #0: loss = 1.29347 (* 1 = 1.29347 loss)
I0713 17:42:20.060201  6493 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0713 17:43:07.612068  6493 solver.cpp:235] Iteration 50, loss = 1.16835
I0713 17:43:07.612412  6493 solver.cpp:255]     Train net output #0: loss = 1.16835 (* 1 = 1.16835 loss)
I0713 17:43:07.612689  6493 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0713 17:43:55.216481  6493 solver.cpp:235] Iteration 60, loss = 1.06255
I0713 17:43:55.216944  6493 solver.cpp:255]     Train net output #0: loss = 1.06255 (* 1 = 1.06255 loss)
I0713 17:43:55.217069  6493 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0713 17:44:42.775416  6493 solver.cpp:235] Iteration 70, loss = 1.47292
I0713 17:44:42.775751  6493 solver.cpp:255]     Train net output #0: loss = 1.47292 (* 1 = 1.47292 loss)
I0713 17:44:42.776046  6493 sgd_solver.cpp:106] Iteration 70, lr = 0.001
I0713 17:45:30.331249  6493 solver.cpp:235] Iteration 80, loss = 1.68133
I0713 17:45:30.331588  6493 solver.cpp:255]     Train net output #0: loss = 1.68133 (* 1 = 1.68133 loss)
I0713 17:45:30.331723  6493 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0713 17:46:17.926605  6493 solver.cpp:235] Iteration 90, loss = 1.17974
I0713 17:46:17.926947  6493 solver.cpp:255]     Train net output #0: loss = 1.17974 (* 1 = 1.17974 loss)
I0713 17:46:17.927191  6493 sgd_solver.cpp:106] Iteration 90, lr = 0.001
I0713 17:47:05.477949  6493 solver.cpp:235] Iteration 100, loss = 1.16226
I0713 17:47:05.478348  6493 solver.cpp:255]     Train net output #0: loss = 1.16226 (* 1 = 1.16226 loss)
I0713 17:47:05.478586  6493 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0713 17:47:53.045765  6493 solver.cpp:235] Iteration 110, loss = 1.28845
I0713 17:47:53.046149  6493 solver.cpp:255]     Train net output #0: loss = 1.28845 (* 1 = 1.28845 loss)
I0713 17:47:53.046439  6493 sgd_solver.cpp:106] Iteration 110, lr = 0.001
I0713 17:48:40.596344  6493 solver.cpp:235] Iteration 120, loss = 1.50325
I0713 17:48:40.596663  6493 solver.cpp:255]     Train net output #0: loss = 1.50325 (* 1 = 1.50325 loss)
I0713 17:48:40.596796  6493 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0713 17:49:28.199036  6493 solver.cpp:235] Iteration 130, loss = 1.11058
I0713 17:49:28.199388  6493 solver.cpp:255]     Train net output #0: loss = 1.11058 (* 1 = 1.11058 loss)
I0713 17:49:28.199499  6493 sgd_solver.cpp:106] Iteration 130, lr = 0.001
I0713 17:50:15.761621  6493 solver.cpp:235] Iteration 140, loss = 1.79032
I0713 17:50:15.761981  6493 solver.cpp:255]     Train net output #0: loss = 1.79032 (* 1 = 1.79032 loss)
I0713 17:50:15.762085  6493 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0713 17:51:03.338533  6493 solver.cpp:235] Iteration 150, loss = 0.963379
I0713 17:51:03.338871  6493 solver.cpp:255]     Train net output #0: loss = 0.963379 (* 1 = 0.963379 loss)
I0713 17:51:03.339115  6493 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0713 17:51:50.918790  6493 solver.cpp:235] Iteration 160, loss = 1.15879
I0713 17:51:50.919112  6493 solver.cpp:255]     Train net output #0: loss = 1.15879 (* 1 = 1.15879 loss)
I0713 17:51:50.919359  6493 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0713 17:52:38.511404  6493 solver.cpp:235] Iteration 170, loss = 0.866312
I0713 17:52:38.511788  6493 solver.cpp:255]     Train net output #0: loss = 0.866312 (* 1 = 0.866312 loss)
I0713 17:52:38.512061  6493 sgd_solver.cpp:106] Iteration 170, lr = 0.001
I0713 17:53:26.079893  6493 solver.cpp:235] Iteration 180, loss = 1.22304
I0713 17:53:26.080282  6493 solver.cpp:255]     Train net output #0: loss = 1.22304 (* 1 = 1.22304 loss)
I0713 17:53:26.080523  6493 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0713 17:54:13.666700  6493 solver.cpp:235] Iteration 190, loss = 1.00456
I0713 17:54:13.667098  6493 solver.cpp:255]     Train net output #0: loss = 1.00456 (* 1 = 1.00456 loss)
I0713 17:54:13.667219  6493 sgd_solver.cpp:106] Iteration 190, lr = 0.001
I0713 17:54:56.574578  6493 solver.cpp:352] Iteration 200, Testing net (#0)
I0713 17:58:10.094040  6493 solver.cpp:419]     Test net output #0: loss = 1.30468 (* 1 = 1.30468 loss)
I0713 17:58:11.442456  6493 solver.cpp:235] Iteration 200, loss = 1.65273
I0713 17:58:11.442673  6493 solver.cpp:255]     Train net output #0: loss = 1.65273 (* 1 = 1.65273 loss)
I0713 17:58:11.442821  6493 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0713 17:58:59.025554  6493 solver.cpp:235] Iteration 210, loss = 0.816059
I0713 17:58:59.025943  6493 solver.cpp:255]     Train net output #0: loss = 0.816059 (* 1 = 0.816059 loss)
I0713 17:58:59.026197  6493 sgd_solver.cpp:106] Iteration 210, lr = 0.001
I0713 17:59:46.574992  6493 solver.cpp:235] Iteration 220, loss = 1.46234
I0713 17:59:46.575378  6493 solver.cpp:255]     Train net output #0: loss = 1.46234 (* 1 = 1.46234 loss)
I0713 17:59:46.575494  6493 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0713 18:00:34.085682  6493 solver.cpp:235] Iteration 230, loss = 1.09307
I0713 18:00:34.086040  6493 solver.cpp:255]     Train net output #0: loss = 1.09307 (* 1 = 1.09307 loss)
I0713 18:00:34.086156  6493 sgd_solver.cpp:106] Iteration 230, lr = 0.001
I0713 18:01:21.682215  6493 solver.cpp:235] Iteration 240, loss = 0.967451
I0713 18:01:21.682674  6493 solver.cpp:255]     Train net output #0: loss = 0.967451 (* 1 = 0.967451 loss)
I0713 18:01:21.682931  6493 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0713 18:02:09.244067  6493 solver.cpp:235] Iteration 250, loss = 1.05817
I0713 18:02:09.244441  6493 solver.cpp:255]     Train net output #0: loss = 1.05817 (* 1 = 1.05817 loss)
I0713 18:02:09.244729  6493 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0713 18:02:56.829264  6493 solver.cpp:235] Iteration 260, loss = 1.5803
I0713 18:02:56.829654  6493 solver.cpp:255]     Train net output #0: loss = 1.5803 (* 1 = 1.5803 loss)
I0713 18:02:56.829766  6493 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0713 18:03:44.398720  6493 solver.cpp:235] Iteration 270, loss = 1.06304
I0713 18:03:44.399153  6493 solver.cpp:255]     Train net output #0: loss = 1.06304 (* 1 = 1.06304 loss)
I0713 18:03:44.399417  6493 sgd_solver.cpp:106] Iteration 270, lr = 0.001
I0713 18:04:31.990109  6493 solver.cpp:235] Iteration 280, loss = 0.994219
I0713 18:04:31.990483  6493 solver.cpp:255]     Train net output #0: loss = 0.994219 (* 1 = 0.994219 loss)
I0713 18:04:31.990589  6493 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0713 18:05:19.579196  6493 solver.cpp:235] Iteration 290, loss = 0.798217
I0713 18:05:19.579524  6493 solver.cpp:255]     Train net output #0: loss = 0.798217 (* 1 = 0.798217 loss)
I0713 18:05:19.579644  6493 sgd_solver.cpp:106] Iteration 290, lr = 0.001
I0713 18:06:07.129338  6493 solver.cpp:235] Iteration 300, loss = 0.83289
I0713 18:06:07.129665  6493 solver.cpp:255]     Train net output #0: loss = 0.83289 (* 1 = 0.83289 loss)
I0713 18:06:07.129777  6493 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0713 18:06:54.693402  6493 solver.cpp:235] Iteration 310, loss = 1.73084
I0713 18:06:54.693769  6493 solver.cpp:255]     Train net output #0: loss = 1.73084 (* 1 = 1.73084 loss)
I0713 18:06:54.693881  6493 sgd_solver.cpp:106] Iteration 310, lr = 0.001
I0713 18:07:42.327157  6493 solver.cpp:235] Iteration 320, loss = 1.20503
I0713 18:07:42.327503  6493 solver.cpp:255]     Train net output #0: loss = 1.20503 (* 1 = 1.20503 loss)
I0713 18:07:42.327767  6493 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0713 18:08:29.926476  6493 solver.cpp:235] Iteration 330, loss = 0.782285
I0713 18:08:29.926916  6493 solver.cpp:255]     Train net output #0: loss = 0.782285 (* 1 = 0.782285 loss)
I0713 18:08:29.927148  6493 sgd_solver.cpp:106] Iteration 330, lr = 0.001
I0713 18:09:17.535320  6493 solver.cpp:235] Iteration 340, loss = 1.55006
I0713 18:09:17.535727  6493 solver.cpp:255]     Train net output #0: loss = 1.55006 (* 1 = 1.55006 loss)
I0713 18:09:17.535840  6493 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0713 18:10:05.107610  6493 solver.cpp:235] Iteration 350, loss = 0.883042
I0713 18:10:05.107993  6493 solver.cpp:255]     Train net output #0: loss = 0.883042 (* 1 = 0.883042 loss)
I0713 18:10:05.108100  6493 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0713 18:10:52.709818  6493 solver.cpp:235] Iteration 360, loss = 0.79635
I0713 18:10:52.710187  6493 solver.cpp:255]     Train net output #0: loss = 0.79635 (* 1 = 0.79635 loss)
I0713 18:10:52.710305  6493 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0713 18:11:40.291687  6493 solver.cpp:235] Iteration 370, loss = 0.90753
I0713 18:11:40.292078  6493 solver.cpp:255]     Train net output #0: loss = 0.90753 (* 1 = 0.90753 loss)
I0713 18:11:40.292353  6493 sgd_solver.cpp:106] Iteration 370, lr = 0.001
I0713 18:12:27.858803  6493 solver.cpp:235] Iteration 380, loss = 1.10735
I0713 18:12:27.859211  6493 solver.cpp:255]     Train net output #0: loss = 1.10735 (* 1 = 1.10735 loss)
I0713 18:12:27.859498  6493 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0713 18:13:15.453608  6493 solver.cpp:235] Iteration 390, loss = 0.727647
I0713 18:13:15.453943  6493 solver.cpp:255]     Train net output #0: loss = 0.727647 (* 1 = 0.727647 loss)
I0713 18:13:15.454048  6493 sgd_solver.cpp:106] Iteration 390, lr = 0.001
I0713 18:13:58.334667  6493 solver.cpp:352] Iteration 400, Testing net (#0)
I0713 18:17:12.130890  6493 solver.cpp:419]     Test net output #0: loss = 1.03492 (* 1 = 1.03492 loss)
I0713 18:17:13.473902  6493 solver.cpp:235] Iteration 400, loss = 1.04547
I0713 18:17:13.474117  6493 solver.cpp:255]     Train net output #0: loss = 1.04547 (* 1 = 1.04547 loss)
I0713 18:17:13.474405  6493 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0713 18:18:01.079958  6493 solver.cpp:235] Iteration 410, loss = 1.1051
I0713 18:18:01.080308  6493 solver.cpp:255]     Train net output #0: loss = 1.1051 (* 1 = 1.1051 loss)
I0713 18:18:01.080567  6493 sgd_solver.cpp:106] Iteration 410, lr = 0.001
I0713 18:18:48.632704  6493 solver.cpp:235] Iteration 420, loss = 0.863962
I0713 18:18:48.633162  6493 solver.cpp:255]     Train net output #0: loss = 0.863962 (* 1 = 0.863962 loss)
I0713 18:18:48.633360  6493 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0713 18:19:36.172736  6493 solver.cpp:235] Iteration 430, loss = 1.39345
I0713 18:19:36.173063  6493 solver.cpp:255]     Train net output #0: loss = 1.39345 (* 1 = 1.39345 loss)
I0713 18:19:36.173174  6493 sgd_solver.cpp:106] Iteration 430, lr = 0.001
